{"cells":[{"cell_type":"markdown","metadata":{"id":"x6uo6qdk7lly"},"source":["https://pytorch.org/tutorials/beginner/ptcheat.html\n","\n","https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n","\n","https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n","\n","https://pytorch.org/tutorials/beginner/translation_transformer.html\n","\n","https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OQ5rtrlGw7_P"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","# אימון מודל טקסט\n","\n","## התקנת ספריות\n","\n","נתקין את הספריות הדרושות, רובן כבר מותקנות על _colab_ \n","ולא נצטרך להתקין אותם מ_pip_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5502,"status":"ok","timestamp":1676648664713,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"W9R6V3WgBn0g","outputId":"b40e07a3-490c-4aa3-b665-fda367c5a714"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchdata\n","  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.25.1)\n","Collecting portalocker>=2.0.0\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.13.1+cu116)\n","Collecting urllib3>=1.25\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n","Installing collected packages: urllib3, portalocker, torchdata\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed portalocker-2.7.0 torchdata-0.5.1 urllib3-1.26.14\n"]}],"source":["%pip install torchdata\n","exit()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zmS2gR8Bu8u"},"outputs":[],"source":["import torchtext\n","import torch\n","import torchdata\n","from torchtext.datasets import AG_NEWS\n"]},{"cell_type":"markdown","metadata":{"id":"fewhG9WSz9mW"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","###שימוש במאגרי מידע\n","`AG_NEWS` \n","זה אובייקט איטרבילי, כך שניתן לעבור על הטקסט וסוג החדשות שהוא נותן \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymM9aVTdz9SF"},"outputs":[],"source":["iter_text = iter(AG_NEWS(split=\"test\"))\n","\n","print(next(iter_text))\n","print(next(iter_text))\n","print(next(iter_text))"]},{"cell_type":"markdown","metadata":{"id":"JAITqiTx44Fi"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","## יצירת טוקנים\n","בשלב ראשון נרצה לפצל את הטקסט ליחידות _tokens_ \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1676494133853,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"ZNzBoXdFL88e","outputId":"a8c32eeb-09f4-4fab-90fa-eeb70079ee46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction Unit Helps Forecast Wildfires (AP) AP - It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already he knows what the day will bring. Lightning will strike in places he expects. Winds will pick up, moist places will dry and flames will roar.\n","['prediction', 'unit', 'helps', 'forecast', 'wildfires', '(', 'ap', ')', 'ap', '-', 'it', \"'\", 's', 'barely', 'dawn', 'when', 'mike', 'fitzpatrick', 'starts', 'his', 'shift', 'with', 'a', 'blur', 'of', 'colorful', 'maps', ',', 'figures', 'and', 'endless', 'charts', ',', 'but', 'already', 'he', 'knows', 'what', 'the', 'day', 'will', 'bring', '.', 'lightning', 'will', 'strike', 'in', 'places', 'he', 'expects', '.', 'winds', 'will', 'pick', 'up', ',', 'moist', 'places', 'will', 'dry', 'and', 'flames', 'will', 'roar', '.']\n"]}],"source":["from torchtext.data.utils import get_tokenizer\n","\n","tokenizer = get_tokenizer('basic_english')\n","text = next(iter_text)[1]\n","print(text)\n","print(tokenizer(text))"]},{"cell_type":"markdown","metadata":{"id":"4at27ruI6PMo"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","## יצירת מילון\n","בשביל שהמודל יצליח לעבוד עם טקסט,דבר ראשון נייצג כל מילה בתור מספר. \n","לשם כך יש אובייקט מיוחד `vocab` שתפקידו לתת מספר לכל המלים. \n","נשים לב שכדאי לתת למילון ערך דיפולטיבי עבור מילים שלא במילון, בשביל שנוכל לנתח מילים שלא מופיעות במילון."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":739,"status":"ok","timestamp":1676495412850,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"QaUjNKUP5S9B","outputId":"c9732a45-adc5-43e6-85e4-c025e91ef0cf"},"outputs":[{"data":{"text/plain":["[772, 2312, 731, 0]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from torchtext.vocab import build_vocab_from_iterator\n","def yield_tokens(data_iter):\n","    for _, text in data_iter:\n","        yield tokenizer(text)\n","\n","vocab = build_vocab_from_iterator(yield_tokens(iter_text), specials=[\"<unk>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])\n","\n","\n","vocab(['unit', 'helps', 'forecast','wordNotApper'])"]},{"cell_type":"markdown","metadata":{"id":"B2K8y7fL9RgN"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","# הפיכת מאגר הטקסט לטנזורים\n","נשתמש באובייקט בשם `DataLoader` \n","שעובר על כל הדאטה ומחזיר אותו כקבוצות, _batchs_ \n","של טנזורים, אותם נשלח למודל לאימון. \n","\n","הפונקציה הזו תחזיר 3 טנזורים:\n","- `label_list` רשימה של כל התגיות  בקבוצה\n","- `offsets` רשימה שמציינת איפה מתחיל כל משפט בטקסט\n","- `text_list` טנזור אחד שמכיל את הטקסטים\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kho505lT6pg7"},"outputs":[],"source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","    for (_label, _text) in batch:\n","         label_list.append(int(_label)-1)\n","         processed_text = torch.tensor(\n","             vocab(tokenizer(_text)), \n","             dtype=torch.int64)\n","         text_list.append(processed_text)\n","         offsets.append(processed_text.size(0))\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0) \n","    text_list = torch.cat(text_list) \n","    return label_list.to(DEVICE), text_list.to(DEVICE), offsets.to(DEVICE) "]},{"cell_type":"markdown","metadata":{"id":"9cu24V_0dAjJ"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","## הפיכת כל הדאטה לטנזורים\n","`DataLoader` \n","זה אובייקט שאוסף את כל הדאטא וע\"י הפונקציה \n","`collate_fn` \n","הוא הופך את המידע לטנזורים."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtERHGB8dX2E"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","train_iter = AG_NEWS(split='train')\n","dataloader = DataLoader(train_iter, batch_size=2, shuffle=False, collate_fn=collate_batch)\n","iter_dataloader = iter(dataloader)\n","print(next(iter_dataloader))\n","print(next(iter_dataloader))\n","print(next(iter_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WlyWu8ErfPQ5"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Mui-UiIoIeWI"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","# יצירת רשת נוירונים\n","\n","### מרכיבי הרשת\n","- `embedding` - שכבה שלוקחת כל מילה ומציגה אותה בתור וקטור מספרים, בצורה כזו ניתן להבין אילו מהמילים קרובות זו לזו. במהלך ריצת הרשת השכבה הזו גם מתעדכנת ויכולה להבין אילו מילים רחוקות אחת מהשניה ואלו קרובות\n","- `Linear` שיכבה ליניארית אחת\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qKk-UZ_UIoOC"},"outputs":[],"source":["from torch import nn\n","\n","class TextClassificationModel(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim, num_class):\n","        super(TextClassificationModel, self).__init__()\n","        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n","        self.fc = nn.Linear(embed_dim, num_class)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        self.fc.bias.data.zero_()\n","\n","    def forward(self, text, offsets):\n","        embedded = self.embedding(text, offsets)\n","        return self.fc(embedded)"]},{"cell_type":"markdown","metadata":{"id":"JmykF8O_qEeb"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","# אימון המודל"]},{"cell_type":"markdown","metadata":{"id":"mIKSJua4qaro"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","### יצירת מודל ופרמטרים"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcfy80lrqgUO"},"outputs":[],"source":["from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","\n","\n","\n","#create model\n","train_iter = AG_NEWS(split='train')\n","num_class = len(set([label for (label, text) in train_iter]))\n","vocab_size = len(vocab)\n","emsize = 64 #size of vector for every word\n","model = TextClassificationModel(vocab_size, emsize, num_class).to(DEVICE)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fT0BeNTbqydg"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","## יצירת מרכיבים לאימון\n","בשביל האימון אנחנו צריכים:\n","- `optimizer` פונקציית אופיטימיזציה שתעדכן את המשקולות במודל\n","- `criterion` \n","- `scheduler` \\\n","חוץ מזה נצטרך היפרפרמטרים:\n","- `EPOCHS` בכמה מחזורים נעשה את האימון, כל מחזור הוא תהליך אימון ואז הערכה של התוצאות\n","- `LR` שיקבע לפונקציית אופטימיזציה את גודל הצעד שצריך לעשות כל פעם\n","- `BATCH_SIZE` קובע בתוך תהליך האימון כל כמה זמן לרוץ ואז לעדכן את הערכים של המודל\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4FKc3TeAHvS"},"outputs":[],"source":["# Hyperparameters\n","EPOCHS = 10 # epoch\n","LR = 5  # learning rate\n","BATCH_SIZE = 64 # batch size for training\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n","criterion = torch.nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n","total_accu = None\n","train_iter, test_iter = AG_NEWS()\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","num_train = int(len(train_dataset) * 0.95)\n","split_train_, split_valid_ = \\\n","    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n","\n","train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n","                              shuffle=True, collate_fn=collate_batch)\n","valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n","                              shuffle=True, collate_fn=collate_batch)\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n","                             shuffle=True, collate_fn=collate_batch)"]},{"cell_type":"markdown","metadata":{"id":"jStxkuqlCu_P"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","## פונקציית אימון והערכה\n","ניצור פונקציית אימון שתעבור כל פעם על סט ערכים ("]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JU3FfoPEqKDF"},"outputs":[],"source":["import time\n","\n","def train(dataloader):\n","    model.train()\n","    total_acc, total_count = 0, 0\n","    log_interval = 500\n","    start_time = time.time()\n","\n","    for idx, (label, text, offsets) in enumerate(dataloader):\n","        optimizer.zero_grad()\n","        predicted_label = model(text, offsets)\n","        loss = criterion(predicted_label, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","        optimizer.step()\n","        total_acc += (predicted_label.argmax(1) == label).sum().item()\n","        total_count += label.size(0)\n","        if idx % log_interval == 0 and idx > 0:\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches '\n","                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n","                                              total_acc/total_count))\n","            total_acc, total_count = 0, 0\n","            start_time = time.time()\n","\n","def evaluate(dataloader):\n","    model.eval()\n","    total_acc, total_count = 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (label, text, offsets) in enumerate(dataloader):\n","            predicted_label = model(text, offsets)\n","            loss = criterion(predicted_label, label)\n","            total_acc += (predicted_label.argmax(1) == label).sum().item()\n","            total_count += label.size(0)\n","    return total_acc/total_count\n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oH-c1JOA1Dk7"},"outputs":[],"source":["for epoch in range(1, EPOCHS + 1):\n","    epoch_start_time = time.time()\n","    train(train_dataloader)\n","    accu_val = evaluate(valid_dataloader)\n","    if total_accu is not None and total_accu > accu_val:\n","      scheduler.step()\n","    else:\n","       total_accu = accu_val\n","    print('-' * 59)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | '\n","          'valid accuracy {:8.3f} '.format(epoch,\n","                                           time.time() - epoch_start_time,\n","                                           accu_val))\n","    print('-' * 59)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNgpz7MGTv+wOZyloKj621U","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
