{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# !cp 'drive/MyDrive/Colab Notebooks/Basic-principles-nn-pythorch/plot_functin.py' ."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mMTo4h-ZVHfn"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","# בניית רשת נויירונים\n","\n","בניית רשת נויירונים היא תהליך המורכב משלוש שלבים: \n","**א.** \n","בניית הרשת ע\"י שירשור של שכבות שונות\n","**ב.** \n","אימון הרשת, ע\"י שימוש בפונקציית העלות _\n","_loss function_\n","ובפונקציית האופטימיזציה \n","_opimazer_\n","**ג.**\n"," בדיקת הרשת מול מידע שאותו היא לא ראתה בתהליך האימון \n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import torch\n","lin = torch.nn.Linear(10,1)\n","class NN(torch.nn.Module):\n","    def __init__(self):\n","        super(NN,self).__init__()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class '__main__.NN'>\n","<class 'torch.nn.modules.linear.Linear'>\n"]}],"source":["nn = NN()\n","print(type(nn))\n","print(type(lin))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","## יצירת מודל\n","מודל הוא שירשור של פונקציות, מורכבות ככול שיהיו, כל שיכבה היא בעצמה מודל?\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2974,"status":"ok","timestamp":1677912846967,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"2G5--wS2Wm61","outputId":"4bdda306-448d-4657-9b4a-8c02ab926a26"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","## יצירת מודל\n","מודל הוא שירשור של פונקציות, מורכבות ככול שיהיו, כל שיכבה היא בעצמה מודל?\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":308,"status":"ok","timestamp":1677912853520,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"SScVJM-nVHfs"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mTools\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_3d_model\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"]}],"source":["import torch\n","import matplotlib.pyplot as plt\n","from Tools import plot_3d_model"]},{"cell_type":"markdown","metadata":{"id":"iaTvRqkKVHfu"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","## יצירת מודל\n","מודל הוא שירשור של פונקציות, מורכבות ככול שיהיו, כל שיכבה היא בעצמה מודל?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1677912899479,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"8L0BSKjGVHfu"},"outputs":[],"source":["import torch\n","\n","conv_1 = torch.nn.Conv2d(1, 6, 5)\n","conv_2 = torch.nn.Conv2d(6, 16, 5)\n","max_pool_1 = torch.nn.MaxPool2d(2)\n","max_pool_2 = torch.nn.MaxPool2d(2)\n","linear_1 = torch.nn.Linear(16 * 5 * 5, 120)\n","linear_2 = torch.nn.Linear(120, 84)\n","linear_3 = torch.nn.Linear(84, 10)\n","activate_1 = torch.nn.ReLU()\n","activate_2 = torch.nn.ReLU()\n","\n","\n","def model(input_data):\n","    y = max_pool_1(input_data)\n","    y = conv_1(y)\n","    y = max_pool_2(y)\n","    y = conv_2(y)\n","    y = linear_1(y)\n","    y = activate_1(y)\n","    y = linear_2(y)\n","    y = activate_2(y)\n","    y = linear_3(y)\n","    return y\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677912900372,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"OL8g-ZxvVHfv"},"outputs":[],"source":["x = torch.rand((100, 400, 120))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iTkpp2s5VHfv"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","### שכבה ליניארית\n","שיכבה ליניארית היא פונקציה אפינית \n","\n","$$\n","\\\\ \\text{Lin}:ℝ^i\\to ℝ^o\n","\\\\ \\text{Lin}(x) = Wx+b\n","$$\n","\n","\n","ע\"מ שהשכבה תיהיה מוגדרת גם על אוסף של וקטורים , כותבים אותה מעט שונה \n","$$\n","\\\\ \\text{Lin}:(ℝ^i)^n\\to (ℝ^o)^n\n","\\\\ \\text{Lin}(x) = xW.T+b  \n","$$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1677912901699,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"h-w1I91rVHfv","outputId":"c1c19e65-c4c5-4379-e080-aa4d3dcb97ad"},"outputs":[],"source":["lin_layer = torch.nn.Linear(2, 2)\n","\n","x = torch.rand(10, 2)\n","print(\n","    f\"\"\"\n","{x=},\n","{lin_layer(x)=}\n","\"\"\"\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677912902092,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"nUB7LEoiVHfw","outputId":"240a6b40-b1e2-4526-f7b0-b8aa26eb0f0e"},"outputs":[],"source":["W = lin_layer.weight.data\n","b = lin_layer.bias.data\n","print(\n","    f\"\"\"\n","{x=},\n","{W=},\n","{b=},\n","{x@W.T+b=},\n","\"\"\"\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"47H6OlVCVHfw"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","אפשר לראות כל שיכבה ליניארית כתת מרחב אפיני. \n","ב\n","$R$\n","זה יראה ככה:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847},"executionInfo":{"elapsed":5640,"status":"ok","timestamp":1677912907728,"user":{"displayName":"Avreymi Asraf","userId":"16756496936831521102"},"user_tz":-120},"id":"KPX43QAdVHfw","outputId":"ce32fc5f-a17d-4cc4-d20f-c68532d2470b"},"outputs":[],"source":["lin_layer = torch.nn.Linear(2, 1)\n","cordinnet = [[num, num] for num in range(15)]\n","x = torch.tensor(cordinnet, dtype=torch.float32)\n","y = lin_layer(x).detach()\n","plot_3d_model(lin_layer, x, y)\n"]},{"cell_type":"markdown","metadata":{"id":"t-0JoHmrVHfw"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","### שיכבת אקטיבציה\n","\n","שיכבת אקטיבציה היא פונקציה (לא לינארית ע\"פ רוב) שמופעלת על הקלט. בדרך כלל נרכיב שיכבה לינארית ושיכבת אקטיבציה ביחד, כך נקבל רשת שיכולה לקרב לא רק פונקציות ליניאריות. (כי הרכבה של פונקציות ליניאריות ליניארית)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axis = plt.subplots(3, 3, figsize=(15, 15))\n","plt.setp(axis, xlim=(-3, 3), ylim=(-1.5, 1.5))\n","activate_functions = {\n","    \"relu\": (torch.nn.functional.relu, axis[0][0]),\n","    \"hardtanh\": (torch.nn.functional.hardtanh, axis[0][1]),\n","    \"elu\": (torch.nn.functional.elu, axis[0][2]),\n","    \"softmax\": (lambda x: torch.nn.functional.softmax(x,dim=0), axis[1][0]),\n","    \"log_softmax\": (lambda x: torch.nn.functional.log_softmax(x, dim=0), axis[1][1]),\n","    \"tanh\": (torch.tanh, axis[1][2]),\n","    \"normalize\": (lambda x: torch.nn.functional.normalize(x, dim=0), axis[2][0]),\n","    \"silu\": (torch.nn.functional.silu, axis[2][1]),\n","}\n","x = torch.linspace(-3, 3, 50)\n","for label, func_and_ax in activate_functions.items():\n","    func = func_and_ax[0]\n","    ax = func_and_ax[1]\n","    ax.plot(x, func(x).detach(), label=label)\n","    ax.grid(True)\n","    ax.legend()\n"]},{"cell_type":"markdown","metadata":{"id":"qnLLtHZ4VHfx"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","### שיכבת הטמעה  Embedding Layer \n","\n","שכבת הטמעה לוקחת יצוג של מילה שהוא מספר בודד ומציגה אותו כוקטור מספרים. \n","יצוג מאפשר למפות מילים למספרים בצורה יותר חכמה, לדוגמה, מילים דומות יכולות להיות קרובות מבחינה וקטורית"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","#### הפיכת מילים לטוקנים ויצירת אוצר מילים"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torchtext import vocab\n","sentence_1 = \"הוא הלך לפארק\"\n","sentence_2 = \"הם נסעו לבית\"\n","sentence_3 = \"אבא ילך לחנות\"\n","sentence_4 = \"היא הגיעה לבית-ספר\"\n","sentences = [sentence_1, sentence_2, sentence_3, sentence_4]\n","words = \" \".join(sentences).split()\n","dictionary = vocab.vocab({words[i]:i+2 for i in range(len(words))})\n","dictionary.set_default_index(0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(dictionary(sentence_1.split()))\n","print(dictionary(sentence_4.split()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["embedding = torch.nn.Embedding(len(words),2)\n","senten_as_num = torch.tensor(dictionary(sentence_1.split()))\n","senten_as_vecotr = embedding(senten_as_num)\n","print(f\"\"\"\n","{senten_as_num=},\n","{senten_as_vecotr=}\n","\"\"\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","#### שכבת הטמעה \n","כל מילה שמיוצגת ע\"י מספר יחיד תיוצג כעת ע\"י וקטור של שני מספרים, כך נוכל למקם מילים קרובות ביחד"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig,axis = plt.subplots(1)\n","for word in dictionary.get_stoi():\n","    word_token = torch.tensor(dictionary([word]))\n","    word_vector = embedding(word_token).detach()[0]\n","    axis.scatter(*word_vector,label= word[::-1])   # reverse the word becuase is hebrow\n","fig.legend(bbox_to_anchor=(1.1, 0.9))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GSDlO9JeVHfx"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","### שיכבת קונבולוציה\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv_layer = torch.nn.Conv1d(1,1,5)\n","print(conv_layer(torch.ones(1,10,dtype=torch.float32)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["m = torch.nn.Conv1d(1, 1, 3, stride=2)\n","input = torch.randn(1, 1, 50)\n","output = m(input)\n","print(output)"]},{"cell_type":"markdown","metadata":{"id":"XkE_7barVHfx"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","## הרכבת שכבות"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","### שיכבה לינארית ופונקציית אקטיבציה - _Perceptron_"]},{"cell_type":"markdown","metadata":{"id":"UTXxIyhGVHfx"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","### הרכבת שכבות לזיהוי תמונה"]},{"cell_type":"markdown","metadata":{"id":"Pd4cOmlpVHfx"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","### הרכבת שכבות לעוד תפקיד?"]},{"cell_type":"markdown","metadata":{"id":"EDl63uplVHfx"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","## יצירת מודל דרך ירושה מ`nn.models`"]},{"cell_type":"markdown","metadata":{"id":"x4qPoDnYVHfy"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","##"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["## רשתות נוירונים _Neural network_\n","\n","כעת כשאנחנו קצת יודעים איך להשתמש ב_autograd_,  נראה איך רשתות נויירונים משתמשות ב_autograd_ בשביל לבנות מודלים ולאמן אותם. כל אובייקט מסוג `nn.Module` מכיל שכבות שונות , ופונקציה `forward(input)` שמקבלת קלט ומחזירה פלט.  \n","\n","לדוגמה נסתכל על מבנה הרשת הזאת בשם _convnet_ שמיועדת למיין תמונות של ספרות בכתב יד (_calssifies_):\n","\n","![image.png](attachment:image.png)\n","\n","זאת רשת פשוטה לחישוב קדימה _feed-forward_  ❗היא מקבלת תמונה כפלט, מעבירה אותה דרך כמה שכבות אחת אחרי השניה ובסוף מדפיסה כפלט איזה ספרה היא זיהתה. \n","\n","\n","תהליך האימון הטיפוסי לרשת כזו הוא כדלהלן:  \n","\n","- מגדירים רשת נוירונים עם משקלים אקראיים ניתנים לשינוי.\n","- מעבר על מאגר מידע של קלט, וחישוב שלו ברשת\n","- חישוב הפער בן המידע הנכון למידע שהתקבל מהרשת _loss_\n","- הגדרת הגרדיאנט לכל שיכבה ברשת \n","- עידכון המשקולות ברשת, על פי רוב באמצעות נוסחה הנוסחה הפשוטה הזאת `weight = weight - learning_rate * gradient`\n"]},{"cell_type":"markdown","metadata":{},"source":["## הגדרת רשת נויירונים CNN \n","בקוד להלן ניצור אובייקט שיהווה רשת הנויירונים שלנו\n","\n","בקישור הזה תוכלו להבין יותר לעומק מה זה \n","[conv2d](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__() #❗\n","        # 1 input image channel, 6 output channels, 5x5 square convolution\n","        # kernel\n","        self.conv1 = nn.Conv2d(1, 6, 5)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        # an affine operation: y = Wx + b\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension \n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        # Max pooling over a (2, 2) window\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        # If the size is a square, you can specify with a single number\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()\n","print(net)"]},{"cell_type":"markdown","metadata":{},"source":["מספיק להגדיר את פונצקיית ה_forward_ בכל אחד מהאופרטורים שאנו מכירים על טנזורים, ובצורה אוטומטית ה_autograd_ יבצע לנו את פעולת ה_backward_ \n","\n","ניתן לראות את כל הפרמטרים של הרשת ע\"י המתודה `()net.parameters` "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["10\n","torch.Size([6, 1, 5, 5])\n"]}],"source":["params = list(net.parameters())\n","print(len(params))\n","print(params[0].size())  # conv1's .weight"]},{"cell_type":"markdown","metadata":{},"source":["ננסה ליצור קלט רנדומלי בגודל 32X32. \n",">💡\n","שימו לב: הרשת בה אנו משתמשים _letNet_ יכולה לקבל קלט רק מגודל 32X3. אם נרצה להכניס לרשת תמונה אמיתית. צריך לשנות את הגודל שלה ל32X32. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.0280, -0.0630, -0.0096,  0.0222,  0.1022, -0.1546, -0.0195,  0.0110,\n","         -0.0614, -0.0042]], grad_fn=<AddmmBackward0>)\n"]}],"source":["input = torch.randn(1, 1, 32, 32)\n","out = net(input)\n","print(out)"]},{"cell_type":"markdown","metadata":{},"source":["נאפס את כל הגרדיאנטים, ואז נעשה את תהליך הפעפוע לאחר _backpropagtion_. (אנחנו מעבירים לפונקציית ה`backward` כפרמטר טנזור רנדומלי בגודל של הרשת❗) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["net.zero_grad()\n","out.backward(torch.randn(1, 10))"]},{"cell_type":"markdown","metadata":{},"source":[">💡שימו לב: `torch.nn` תומכת רק במיני אצוות 🤯\n","\n","torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\n","\n","For example, nn.Conv2d will take in a 4D Tensor of nSamples x nChannels x Height x Width.\n","\n","If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension."]},{"cell_type":"markdown","metadata":{},"source":["### סיכום:\n","לפני שנמשיך האלה נסכם את כל המחלקות שראינו עד עכשיו\n","#### מחלקות \n"," * `torch.Tensor` - מערך רב מימדי שתומך בפעולות כמו `()backward`  . בנוסף הוא מחזיק את ה`gradient` של הטנזור\n"," * `nn.Module` - רשתות נוירונים, דרך נוחה ליצור רשת עם כל השכבות והפרמטרים בצורה מהירה, אחד מהיתרונות הגדולים הוא שאפשר להריץ את החישובים על הGPU\n"," * `nn.Parameter` - טנזור המהווה חלק מרשת נויירונים \n"," * `autograd.Function` - מכילה את כל ההיסטוריה של כל טנזור בתוך רשת נויירונים, כך ניתן לחשב את הגרדיאנט בקריאה לפונקציה `backward`\n"," \n","#### בשלב זה למדנו \n"," * איך להגדיר רשת נוירונים \n"," * הכנסת קלט והפעלת פונקציית \n"," `backward` על הפלט לאימון המודל \n","\n","#### נותר לנו ללמוד\n","* חישוב השגיאה _loss_ \n","* עידכון המשקלים _weights_ של הרשת \n"," "]},{"cell_type":"markdown","metadata":{},"source":["## פונקציית הפסד  _loss function_\n"," פונקציית הפסד _loss function_ מקבלת כארגומנטים זוג המכיל את הפלט של רשת הנוירונים ואת התשובה הנכונה _(outpot, target)_ \n","ומעריכה את השגיאה בן הפלט שקיבלנו _output_ לפלט הרצוי _target_. \\\n","יש כמה דרכים שונות לחשב את השגיאה, בתוך המודול\n","[`torch.nn`](https://pytorch.org/docs/stable/nn.html#loss-functions) ניתן למצוא כמה מהם,  \n","פונקציית הפסד פשוטה היא\n","[`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) שמחשבת את \n","[הממוצע הריבועי](https://he.wikipedia.org/wiki/%D7%98%D7%A2%D7%95%D7%AA_%D7%A8%D7%99%D7%91%D7%95%D7%A2%D7%99%D7%AA_%D7%9E%D7%9E%D7%95%D7%A6%D7%A2%D7%AA) \n","של ההפרש בן הפלט שקיבלנו לפלט הרצוי \n","\n","לדוגמה"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(1.4069, grad_fn=<MseLossBackward0>)\n"]}],"source":["output = net(input)\n","target = torch.randn(10)  # a dummy target, for example\n","target = target.view(1, -1)  # make it the same shape as output\n","criterion = nn.MSELoss()\n","\n","loss = criterion(output, target)\n","print(loss)"]},{"cell_type":"markdown","metadata":{},"source":["כעת אם נעקוב אחרי ההפרש שחישבנו בתהליך הפיעפוע לאחור _backward_ שמשתמש במאפיין `grad_fn`, נוכל לצייר גרף של כל החישובים שנראה בערך כך:\n","![image.png](attachment:image.png)\n","כעת כשנפעיל את הפוקנציה `()loss.backward` כל המרכיבים בגרף הזה (להוציא את ה_input_ ואת פונקציית ההפסד) יחשבו את תרומתם לשגיאה, וכל הטנזורים שיש להם `requires_grad=True` יהיה להם מאפיין `grad.` שיכיל את ה_gradient_ שלהם, כלומר את כיון ומידת השינוי שצריך לעשות בשביל לצמצם השגיאה.  "]},{"cell_type":"markdown","metadata":{},"source":["לשם המחשה נדגים איך ניתן מתוך טנזור השגיאה לראות את כל התהליך שיצר אותו:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<MseLossBackward0 object at 0x000002211AF0BDF0>\n","<AddmmBackward0 object at 0x000002211AF0AEF0>\n","<AccumulateGrad object at 0x000002212B0E4A00>\n"]}],"source":["print(loss.grad_fn)  # MSELoss\n","print(loss.grad_fn.next_functions[0][0])  # Linear\n","print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"]},{"cell_type":"markdown","metadata":{},"source":["## פיעפוע לאחור _Backprop_ \n","     תזכורת: לאחר שהכנסנו מידע לרשת הנוירונים,קלט, קיבלו את הפלט וחישבנו את השגיאה נרצה כעת לשנות את המשקולות בכל הרשת כך שהשגיאה תקטן. נעשה זאת ע\"י תהליך הפיעפוע לאחור בו נחשב בכל לכל שכבה  את הגרדיאנט שלה (שזה \"הכיון\" אליו היא משנה  את התוצאה) בהמשך לפי הגרדיאנט נשנה את ערכי המשקולות \n","\n","על מנת לעשות את תהליך הפיעפוע לאחור כל מה שצריך לעשות הוא לקרוא לפונצקיה `()loss.backward`. אבל לפני זה צריך לנקות את הגדיאנט שאולי קיים כבר בטנזורים, אחרת הגרדיאנט החדש יתווסף לגרדיאנט הקיים\n","\n","נסתכל ב_bias_ של השכבה _conv1_ השכבה הראשונה במודל, לפני תהליך ה_backprop_ ואחריו:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["conv1.bias.grad before backward\n","tensor([0., 0., 0., 0., 0., 0.])\n","conv1.bias.grad after backward\n","tensor([-0.0115, -0.0146,  0.0195, -0.0203,  0.0169,  0.0161])\n"]}],"source":["net.zero_grad()     # zeroes the gradient buffers of all parameters\n","\n","print('conv1.bias.grad before backward')\n","print(net.conv1.bias.grad)\n","\n","loss.backward()\n","\n","print('conv1.bias.grad after backward')\n","print(net.conv1.bias.grad)"]},{"cell_type":"markdown","metadata":{},"source":["כעת אנחנו יודעים כיצד לחשב את ההשפעה של כל שכבה ברשת לפי וקטור השגיאה  \n","נותר לנו ללמוד איך לעדכן את ערכי המשקולות בכל השכבות\n","\n","\n","#### לקריאה נוספת 📖\n","החבילה `Torch.nn` מכילה מגוון מודלים ופונקציית הפסד, עימם אפשר לבנות רשתות נוירוים שונות. \\\n","רשימה מלאה נמצאת \n","[כאן](https://pytorch.org/docs/stable/nn.html)\n"," "]},{"cell_type":"markdown","metadata":{},"source":["## עידכון המשקולות _Update the weights_ \n","החוק הפשוט ביותר לעידכון המשקולות הוא ה_SGD_ \n","[Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent):\n","\n","```weight = weight - learning_rate * gradient```\n","\n","מכיון שיש לנו את הגדיאנט של כל שכבה אם נרצה לממש אותו נוכל בפשטות לעבור על כל שיכבה ולעדכן את המידע:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["learning_rate = 0.01\n","for f in net.parameters():\n","    f.data.sub_(f.grad.data * learning_rate)"]},{"cell_type":"markdown","metadata":{},"source":["אבל לפעמים נרצה להשתמש בפונקציות עידכון משקולות שונות ומורכבות יותר, במודל `torch.optim` יש מימושים של כל המתודות לעידכון משקולות והשימוש בהם מאוד פשוט:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.optim as optim\n","\n","# create your optimizer\n","optimizer = optim.SGD(net.parameters(), lr=0.01)\n","\n","# in your training loop:\n","optimizer.zero_grad()   # zero the gradient buffers\n","output = net(input)\n","loss = criterion(output, target)\n","loss.backward()\n","optimizer.step()    # Does the update"]},{"cell_type":"markdown","metadata":{},"source":[">💡\n","שימו לב: כמו שהזכרנו לעיל צריך לעדכן בהתחלה את כל הגרדיאנטים ל0, אחרת הגדיאנט החדש יצטבר על הקודם \n","\n"]},{"cell_type":"markdown","metadata":{"id":"-uOBtZ11VHfy"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_tensor(tensor):\n","    \"\"\"print main attribute of tensor\n","    \"\"\"\n","    print(f'\\\n","    data: {tensor.data}\\n \\\n","    requires_grad: {tensor.requires_grad}\\n \\\n","    grad: {tensor.grad}\\n \\\n","    grad_fn: {tensor.grad_fn}\\n \\\n","    is_leaf: {tensor.is_leaf}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","    \n","# רשת נוירונים - _nerual networks_ 🤯\n","> רשת נוירונים  _nerual networks (NN)_ היא קבוצה של פונקציות משורשרות אחת בתוך השניה שמיועדת לעשות פעולת מורכבות מאוד - לדוגמה זיהוי קול, זיהוי תוכן בתמונה, הבנת טקסט ועוד. כמו כל פונקציה מפעילים אותה על פלט -  _input_ כלשהוא ומצפים לפלט -_outpot_  נכון. בPyTorch הקלט והפלט הם טנזורים, ולכן אם נרצה  לבנות רשת שתזהה תמונות נצרך תחילה להציג אותם בתור טנזורים.\n","\n","\n","\n","\n","## מבנה כללי 🧠\n","רשת נויירונים בסיסית מורכבת ממספר שכבות - _layers_  שהם למעשה פונקציות. כל שיכבה מקבלת קלט מהשיכבה שלפניה, מעבדת אותו ומעבירה לשכבה הבאה, כך עד לשכבת הפלט האחרונה. כל רשת נוירונים דורשת גם אימון, כלומר נעביר בתוך הרשת מידע ונשנה את הפרמטרים שבתוך השכבות עד שהרשת תיצור לנו תחזית נכונה.\n","![general.gif](attachment:general.gif)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","### שכבה - _Layer_  🍰 \n","שכבה היא פונקציה כל שהיא, אנחנו נעסוק בשכבות מסוג מאוד בסיסי - שכבה ליניארית.\n","כל שכבה כזו מכילה 3 אלמנטים מרכזיים: פרמטרים משני סוגים - _weights_  זאת מטריצה עם מספר עמודות כגודל הקלט ושורות כגדול הפלט, היא נקראת משקולות ו_baios_ שזה וקטור בגודל הפלט, בנוסף השכבה מכילה פוקנציית אקטיבציה זאת פונקציה שמנרמלת את הפלט, כלומר מחזירה ערכים בתחום מסויים.\n","העברת קלט בשכבה ליניארית היא 3 פעולות:\n","- כפל במשקולות, כלומר כפל במטריצה מימין\n","$xW^t$\n","- הוספת ערך קבוע,_bios_  \n","$xW^t+b$\n","- נירמול של התוצאה בפונקציית אקטיבציה, זאת פונקציה שמנרמלת את המידע שיוצא מהכפל במשקולות. במקרה שלנו נשמתמש ב _Sigmoid_  היא תנרמל לטווח בן  0-1 \n","$$\n","\\text{Sig}\\left(xW^t+b\\right)=Y\n","$$\n","\n","\n","כמו שאמרנו ה_weights_ וה_baios_ הם טנזורים, ולכן פעולת כל שכבה ניתנת לתיאור כפעולות פשוטות של כפל וחיבור וקטורים\n","- הערה 💡: בתמונה המצורפת אין התייחסות לכפל של הוקטור מימין ולשיחלוף המטירצה, אלה נועדו רק כדי לאפשר לשכבה לקלוט וקטור אנכי ולהוציא ג\"כ וקטור אנכי. למען הפשטות התעלמנו מזה\n","![singel_layer_metrix.gif](attachment:singel_layer_metrix.gif) \n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","השכבות מתחלקות לשלושה סוגים:\n","\n","**שכבת כניסה - _Input layer_ 📥** \n","השכבה שמקבלת את המידע, היא צריכה להיות בגודל המידע עצמו, כלומר אם אנחנו נכניס לרשת תמונות בגודל 64X64 שכבת הכניסה תהיה בגודל 64X64.\n","\n","**שכבות מוסתרות - _Hidden layer_ 🙈**\n","אלו שכבות שהגודל שלהם והחיבורים בניהם לא קבועים, הם נקראות שכבות מוסתרות כי אחרי אימון יהיה בהם מערכת קשרים שתיצור תחזית נכונה, אבל אנחנו לא נדע איך היא בנוייה\n","\n","**שכבת פלט - _Output layer_ 📤** שכבת הפלט, היא נותנת את התשובה הסופית ולכן הגודל שלה יהיה כגודל מספר התשובות האפשריות\n","\n","\n","במודל `torch.nn` קיימות הרבה פונקציות שימושיות לצורך בניית רשתות נויירונים, בניהם הפונקציהה `linear` ו `Sigmoid` בהם נשתמש בשכבה שלנו"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn \n","import torch\n","\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(10,10)         #define size of input and outpot  \n","        self.active_func = nn.Sigmoid()\n","        self.fc2 = nn.Linear(10,10)\n","        self.fc3 = nn.Linear(10,10)\n","\n","    def forward(self, x):\n","        y = self.fc1(x)\n","        y = self.active_func(y)\n","        y = self.fc2(y)\n","        y = self.active_func(y)\n","        y = self.fc3(y)\n","        y = self.active_func(y)\n","        return y\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","    \n","נוכל לראות את הפרמטרים שנמצאים בתוך השכבה שיצרנו, הם נוצרים באופן אקראי כשיצרנו את השכבה, בהמשך נראה איך אפשר לעדכן אותם כך שיתנו תשובה\n","נכונה. \\ \n","אפשר לשים לב שה_weight_ זאת מטריצה, וה_bias_ הוא וקטור בגודל הפלט."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[-0.2472, -0.0275,  0.1567, -0.0079,  0.0298,  0.1999, -0.1545, -0.2435,\n","          0.3044,  0.2082],\n","        [ 0.2772, -0.2105, -0.1923, -0.1423, -0.2509, -0.0891, -0.1857, -0.2614,\n","         -0.0659, -0.2986],\n","        [-0.2410,  0.3031, -0.2177, -0.1283,  0.0710,  0.0425, -0.1492,  0.2229,\n","          0.2277, -0.2464],\n","        [ 0.2599, -0.0571, -0.2963, -0.2666, -0.0776,  0.1636,  0.2225, -0.0734,\n","          0.0414, -0.1165],\n","        [-0.2232, -0.2375, -0.0871, -0.1327,  0.1263, -0.1451, -0.1475,  0.1011,\n","          0.2216, -0.0331],\n","        [ 0.0825, -0.1719,  0.1709, -0.2031, -0.2258,  0.0447, -0.2024, -0.1433,\n","          0.2088,  0.1471],\n","        [ 0.1989, -0.2260,  0.2156, -0.3029,  0.2074, -0.1181, -0.2985,  0.1635,\n","          0.1202, -0.0587],\n","        [ 0.2763, -0.0403, -0.2563, -0.2919, -0.3086,  0.0696,  0.1583, -0.1346,\n","         -0.2241,  0.2004],\n","        [ 0.2385, -0.0249,  0.1343,  0.0768, -0.1144,  0.0343,  0.1359, -0.0646,\n","         -0.0393,  0.0330],\n","        [ 0.2855,  0.2584, -0.2493, -0.0939, -0.1701, -0.0992,  0.2463,  0.0753,\n","         -0.0454,  0.0982]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2088,  0.1438, -0.1276,  0.0586,  0.1216,  0.1190, -0.2602,  0.2159,\n","        -0.1477,  0.3107], requires_grad=True)\n"]}],"source":["\n","model = Net()\n","print(model.fc1.weight)\n","print(model.fc1.bias)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0.5725, 0.4995, 0.5539, 0.4647, 0.4458, 0.5397, 0.5462, 0.5256, 0.6237,\n","        0.4613], grad_fn=<SigmoidBackward0>)"]},"metadata":{},"output_type":"display_data"}],"source":["x = torch.tensor(list(range(10)),dtype=torch.float32)\n","\n","model.forward(x)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","בנינו רשת נוירונים שפעולת, היא מקבלת מידע ומפעפעת אותו בשכבות השונות.\n","אבל כמו שאפשר לראות אין לרשת הזו שום משמעות מכיון שהפרמטים בכל השכבות אקראיים לחלוטין. "]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","## אימון הרשת - Trannig 💪\n","כעת המידע שהרשת מוציאה אקראי לחלוטין, בשביל שהוא יהיה בעל משמעות עלינו לשנות את הפרמרטים של הרשתות השונות, כלומר עלינו לעדכן את ה_weights_ והו_baios_ כך שיתנו תוצאה נכונה. \n","את עידכון הפרמטרים לא נעשה באופן ידני (זה קצת קשה) במקום זה יש תהליך שנקרא אימון ובו הרשת מעדכנת את הפרמטרים לבד.\n","\n","בשביל אימון הרשת צריך סט נתונים - _data set_, ברשתות שאנחנו נבנה צריך סט נתונים מתוייג, כלומר כמות גדולה של נתונים כך שלכל קלט יהיה לנו גם את התשובה הנכונה. בדוגמה של רשת שמזהה תוכן בתמונות אנחנו נצטרך כמות גדולה של תמונות כך שלכל תמונה יש גם את התשובה הנכונה מה היא מכילה.\n","כשיש לנו דאטה סט טוב נתחיל באימון הרשת, האימון הוא תהליך איטרטיבי - כלומר חוזר על עצמו, כל מחזור מכיל שני שלבים:\n","\n","### חישוב _Forward Propagation_ 😄\n","בשלב זה האלגוריתם לוקח את המשקולות הנתונים לו (בצעד הראשון אלו משקולות אקראיים) ומחשב את התוצאה עבור מידע מסויים. בדוגמה שלנו - נכניס לרשת תמונה ונקבל את התוצאה \n","\n","### פיעפוע לאחור _Backward Propagation_ 🧐\n","בשלב זה האלגוריתם משווה את התוצאה עם התוצאה הידועה לו כנכונה, ומעדכן את המשקולות באופן פופורציונלי לשגיאה. לצרוך כך צריך שני כלים: \n","**פונקציית הפסד** \n","בשביל להעריך את הטעות\n","ו**גרדיאנט**\n","בשביל לשנות כל שכבה באופן פרפציונלי לטעות.\n","#### פונקציית הפסד - _less function_ 😢\n","היא הצורה להעריך את הטעות, בשלב הזה נעסוק בפונקציית הפסד בסיסית ביותר. סכום ההפרש בן כל הקורדינטות בערך מוחלט. בפרק הבא נתבונן על עוד פונקציות הפסד \n","#### גרדינאט - _gradient decent_ 📉\n","איך האלגורים של הרשת יודע כמה לשנות כל פרמטר בכל שכבה? \n","המידע הזה נמצא בנגזרת של כל שכבה וביתר דיוק בנגזרת החלקית של כל שכבה, כאשר מחילים אותה על כל המשתנים היא נקראת _gradient_ והפונקציה שמוצאת אותה נקראת  \n"," _gradient descent_. בהמשך העמוד יש הרחבה על _gradient descent_ . מה שעלינו לזכור הוא שלכל שכבה ברשת נרצה לדעת מה _gradient_ שלה, בשביל לעדכן את הערכים שלה.   \n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","## לסיכום\n","     מה עלינו לדעת בשביל להמשיך?\n","     -🧠 רשת נוירונים היא שירשור של שכבות 🍰 בהם המידע מפעפע משכבה לשכבה\n","     -💪 בשביל לעדכן את הפרמטרים בשכבות צריך לאמן את הרשת, עם תהליך שכולל חישוב ופיעפוע לאחור 🧐\n","     - בשביל שהפיעפוע לאחור יעבוד כראוי אנחנו צריכים להשיג לכל שכבה את הגרדינט שלה 📉 שזה סוג של נגזרת חלקית \n","     "]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n"," ## אימון עם _PyTorch_\n","\n","\n","נתבונן על מחזור אימון אחד. \n","בדוגמה הזאת נטען מודל מאומן מראש בשם `resnet18` מתוך חבילת המודלים המאומנים `torchvision`. אנחנו ניצור טנזור רנדומלי `data` שייצג תמונה עם 3 ערוצים (RBG), הגובה והרוחב של התמונה הם 64X64 פיקסלים.\n","לתמונה האקראית ניצור גם `label` אקראי שייצג את מה שיש בתמונה. הצורה של המודלים היא (1,1000) ??"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","## _Autograd_\n","\n","_autograd_  הוא כלי שמאפשר לאמן רשתות נויירונים באופן אוטומטי יחסית. בפרק הזה נסביר מה המטרה שלו, איך משתמשים בו ואיך הוא עובד מאחורי הקלעים. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch, torchvision\n","model = torchvision.models.resnet18(pretrained=True)\n","data = torch.rand(1, 3, 64, 64) #ramdom image\n","labels = torch.rand(1, 1000)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","נוכל לראות את כל שכבה ואת המאפיינים שלה ע\"י מעבר על `()model.named_parameters` (יש המון מידע בשכבות, אז לא כדאי להדפיס את כל המשקלים)\n","![image.png](attachment:image.png)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["conv1.weight-> True\n","bn1.weight-> True\n","bn1.bias-> True\n","layer1.0.conv1.weight-> True\n","layer1.0.bn1.weight-> True\n","layer1.0.bn1.bias-> True\n","layer1.0.conv2.weight-> True\n","layer1.0.bn2.weight-> True\n","layer1.0.bn2.bias-> True\n","layer1.1.conv1.weight-> True\n","layer1.1.bn1.weight-> True\n","layer1.1.bn1.bias-> True\n","layer1.1.conv2.weight-> True\n","layer1.1.bn2.weight-> True\n","layer1.1.bn2.bias-> True\n","layer2.0.conv1.weight-> True\n","layer2.0.bn1.weight-> True\n","layer2.0.bn1.bias-> True\n","layer2.0.conv2.weight-> True\n","layer2.0.bn2.weight-> True\n","layer2.0.bn2.bias-> True\n","layer2.0.downsample.0.weight-> True\n","layer2.0.downsample.1.weight-> True\n","layer2.0.downsample.1.bias-> True\n","layer2.1.conv1.weight-> True\n","layer2.1.bn1.weight-> True\n","layer2.1.bn1.bias-> True\n","layer2.1.conv2.weight-> True\n","layer2.1.bn2.weight-> True\n","layer2.1.bn2.bias-> True\n","layer3.0.conv1.weight-> True\n","layer3.0.bn1.weight-> True\n","layer3.0.bn1.bias-> True\n","layer3.0.conv2.weight-> True\n","layer3.0.bn2.weight-> True\n","layer3.0.bn2.bias-> True\n","layer3.0.downsample.0.weight-> True\n","layer3.0.downsample.1.weight-> True\n","layer3.0.downsample.1.bias-> True\n","layer3.1.conv1.weight-> True\n","layer3.1.bn1.weight-> True\n","layer3.1.bn1.bias-> True\n","layer3.1.conv2.weight-> True\n","layer3.1.bn2.weight-> True\n","layer3.1.bn2.bias-> True\n","layer4.0.conv1.weight-> True\n","layer4.0.bn1.weight-> True\n","layer4.0.bn1.bias-> True\n","layer4.0.conv2.weight-> True\n","layer4.0.bn2.weight-> True\n","layer4.0.bn2.bias-> True\n","layer4.0.downsample.0.weight-> True\n","layer4.0.downsample.1.weight-> True\n","layer4.0.downsample.1.bias-> True\n","layer4.1.conv1.weight-> True\n","layer4.1.bn1.weight-> True\n","layer4.1.bn1.bias-> True\n","layer4.1.conv2.weight-> True\n","layer4.1.bn2.weight-> True\n","layer4.1.bn2.bias-> True\n","fc.weight-> True\n","fc.bias-> True\n"]}],"source":["for name, param in model.named_parameters():\n","    print(name, end = \"-> \")\n","    print(param.requires_grad) #if need to update it in Backward Propagation\n","#     print(param) #All the weights of the nets, it's huge\n","    "]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","בשלב הבא נעביר את הקלט (התמונה האקראית שיצרנו) דרך כל אחת משכבות המודל, נקבל בפלט חיזוי מהו תוכן התמונה.\n","פלט החיזוי הוא טנזור שמכיל לכל ליבל את הסיכוי שזה הוא. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prediction = model(data) # forward pass"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 1000])"]},"metadata":{},"output_type":"display_data"}],"source":["prediction.shape"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","נשווה את מה שהמודל חזה ואת מה שידוע לנו שהיא התוצאה הנכונה. נסכום את ההפרש בינהם וכך נוכל לחשב את שיעור הטעות `loss`.\n","\n","בשלב הבא נשנה את המשקולות בהתאמה לשגיאה דרך תהליך הפיעפוע לאחור _backward_ \n","\n","תהליך הפיעפוע לאחור מתחיל ע\"י קריאה למתודה `()backward.` על הטנזור הטעות `loss`. לאחר מכן בצורה אוטומטית _Autograd_ מחשב ומאחסן את הגרדיאנט _gradients_ לכל מודל פרמטר של המודל בתוך המאפיין (_attribute_) `grad.`  של הפרמטר.  \n",">💡 שימו לב - המתודה `()backward.` נגשת לכל שכבה במודל ומכניסה לה את ערך ה\n","_grad_\n",", למרות שהיא נקראת על טנזור ה\n","_loss_  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss = (prediction - labels).sum()\n","loss.backward() # backward pass"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","בשלב הבא נפעיל את תהליך האופטימיזציה על המודל, במקרה הזה נשתמש ב_SGD_ כך שהפרמטרים _learninig rate_ `lr` הוא 0.01 והמומנטום \n","[_momentum_](https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d) \n","הוא 0.9, נכניס את \n","כל הפרמטרים לתוך האופטימייזר.  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","לבסוף קוראים למתודה `()step.` ע\"מ להחיל את ה_gradient descent_ על הפרמטרים. האפטימייזר ישנה את הערכים של כל פרמטר ופרמטר לפי הגרינאנט _gradient_ שנמצא ב`grad.`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optim.step() #gradient descent"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","בשלב הזה סיימנו את כל התהליך של אימון רשת נוירונים. בהמשך הפרק נראה איך הדברים פועלים מבחינה מתמטית. \n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","## מה זה גרדיאנט _gradient_\n"," ע\"מ לשנות את המשקולות בהתאמה לטעות אנו צריכים לדעת לאיזה כיון לשנות את המשקולת, האם הגדלה של המשקולת תגדיל את הפער? או הקטנה של המשקולת תגדיל את הפער? \n","מכיון שמדובר בפונקציה עם הרבה מאוד משתנים עלינו להשתמש בגרדיאנט, שזה וקטור המכיל את כל הנגזרות של כל המשתנים. כך אנחנו יודעים באיזה כיון לשנות את המשקולות. \n","\n","בפונקציה עם שני משתנים ניתן לחשוב על הגרדיאנט כתהליך שמוצא את הנקודה הנמוכה ביותר\n","![image.png](attachment:image.png)\n","בשביל להבין טוב יותר ניתן לראות את הסרטון [הזה](https://www.youtube.com/watch?v=tIeHLnjs5U8) של _3Blue1Brown_"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","### חישוב אוטומטי של ה`grad.` ע\"י _autograd_\n","נראה כיצד _autograd_  משנה את ערכי ה`grad.`\n","ניצור שני טנזורים _a_ ו_b_ עם השדה`requires_grad=True` כך נסמן ל_autograd_ שצריך לעקוב אחרי כל השינויים שקוראים בטנזור הזה "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","a = torch.tensor([2., 3.], requires_grad=True)\n","b = torch.tensor([6., 4.], requires_grad=True)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","ניצור טנזור אחר _Q_ מ _a_ ו _b_\n","\n","\\begin{align}Q = 3a^3 - b^2\\end{align}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["<SubBackward0 at 0x1e50b9711b0>"]},"metadata":{},"output_type":"display_data"}],"source":["Q = 3*a**3 - b**2\n","Q.grad_fn # An object that contains a link to the tesors that created it"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","נניח ש_a_ ו_b_ הם פרמטרים של רשת נויירונים כל שהיא ו_Q_ הוא טנזור השגיאה _loss_, באימון הרשת אנחנו רוצים לחשב את גרדיאנט של הפרמטרים, כלומר הנגזרת של הפער בן הטנזור הנוכחי לטנזור השגיאה לפי המשתנים השונים\n","\n","\\begin{align}\\frac{\\partial Q}{\\partial a} = 9a^2\\end{align}\n","\n","\\begin{align}\\frac{\\partial Q}{\\partial b} = -2b\\end{align}\n","\n","כאשר אנחנו קוראים למתודה `()backward.` על _Q_  בצורה אוטמטית _autograd_ מחשבת את הגרדיאנט ומאחסנת אותו בתוך המאפיין (_attribute_)  `grad.` \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","אנחנו צריכים בצורה מפורשת להעביר טנזור _gradient_ כארגומנט לתוך `()Q.backward`  בגלל שהוא וקטור, הוא מייצג את הגרדיאנט של _Q_, מכיון ביחס לעצמו - ששווה לטנזור אחדות\n","$$\n","\\begin{align}\\frac{dQ}{dQ} = 1\\end{align}\n","$$\n","לחלופין ניתן לסכום את אברי _Q_ ואז לקרוא ל`()Q.sum().backward` בלי להעביר את הגרדיאנט של השגיאה"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["external_grad = torch.tensor([1., 1.])\n","Q.backward(gradient=external_grad)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","כעת נוכל לראות את הגרדיאנט של כל משתנה ומשתנה אצלו ברשת בצורה מפורשת. למעשה במקרה פשוט זה הגדיאנט הוא הנגזרת "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([36., 81.], grad_fn=<MulBackward0>) \n"," --> tensor([36., 81.])\n","tensor([-12.,  -8.], grad_fn=<MulBackward0>) \n"," --> tensor([-12.,  -8.])\n"]}],"source":["# check if collected gradients are correct\n","print(f'{9*a**2} \\n --> {a.grad}')\n","print (f'{-2*b} \\n --> {b.grad}')"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","### תוספת להרחבה - חישוב וקטור בעזרת _autograd_\n","\n","מבחינה מתמטית אם נתונה לנו פונקציה על וקטור $\\vec{y}=f(\\vec{x})$, אזי הגרדיאנט של  $\\vec{y}$ ביחס ל $\\vec{x}$ היא מטריצת יעקוביאן $J$: כלומר זאת     מטריצת הנגזרות - \n","[פה](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/jacobian/v/the-jacobian-matrix) \n"," יש תוספת הסבר\n","$$\n","\\begin{align}J\n","     =\n","      \\left(\\begin{array}{cc}\n","      \\frac{\\partial \\bf{y}}{\\partial x_{1}} &\n","      ... &\n","      \\frac{\\partial \\bf{y}}{\\partial x_{n}}\n","      \\end{array}\\right)\n","     =\n","     \\left(\\begin{array}{ccc}\n","      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n","      \\vdots & \\ddots & \\vdots\\\n","      \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n","      \\end{array}\\right)\\end{align}\n","      $$\n","\n","באופן כללי  `torch.autograd` זה פונקציה שמאפשרת לנו לחשב את הכפל מטריצות עבור וקטור  $\\vec{v}$, נחשב את הכפל\n","$J^{T}\\cdot \\vec{v}$\n","\n","במקרה ש $\\vec{v}$ הוא גרדיאנט של פונקציה רגילה  $l=g\\left(\\vec{y}\\right)$:\n","\n","$$\n","\\begin{align}\\vec{v}=\n","   \\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}\\end{align}\n","$$\n","ואז ע\"י חוק השרשרת של נגזרות  $l$ with respect to $\\vec{x}$:\n","\n","$$\n","\\begin{align}J^{T}\\cdot \\vec{v}=\\left(\\begin{array}{ccc}\n","      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n","      \\vdots & \\ddots & \\vdots\\\\\n","      \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n","      \\end{array}\\right)\\left(\\begin{array}{c}\n","      \\frac{\\partial l}{\\partial y_{1}}\\\\\n","      \\vdots\\\\\n","      \\frac{\\partial l}{\\partial y_{m}}\n","      \\end{array}\\right)=\\left(\\begin{array}{c}\n","      \\frac{\\partial l}{\\partial x_{1}}\\\\\n","      \\vdots\\\\\n","      \\frac{\\partial l}{\\partial x_{n}}\n","      \\end{array}\\right)\\end{align}\n","$$\n","הוקטור יעקובי הזה הוא מה שאנחנו משתמשים בו בדוגמה למעלה,  \n","``external_grad`` represents $\\vec{v}$.\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","### איך `autograd` עובד\n","\n","`autograd` שומר את כל הטנזורים ואת כל הפעולות שעשו עליהם עם התוצאות בגרף מכוון חסר מעגלים (_DAG_), הגרף הזה מורכב \n","[מאובייקטי](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function) \n","פונקציות מיוחדים\n","בו העלים הם הטנזורים שנכנסו _input_   ושורש העץ הוא _output_.  \n","ע\"י מעבר משורש העץ עד תחתיתו ניתן לחשב את הגרדיאנט בעזרת חוק השרשרת.\n","\n","\n","בתהליך ה_forward_ מנגנון ה`autograd` עושה שתי פעולת במקביל: \n","\n","- מחשב את התוצאה של ה_input_ הנוכחי כמו תהליך חישוב רגיל.  \n","- שומר את הפעולות שנעשו בתוך העץ.  \n","\n","כאשר קוראים ל`()backward.` על התוצאה (וקטור ה_output_ שמהווה ראש העץ) אז _autograd_ הולך לראש העץ ועושה את הפעולות הבאות:\n","\n","- מחשב את הגדיאנט של כל פונקציה המאוחסנת ב`grad_fn.`\n","- מכניס את ערך הגרדיאנט לתוך `grad.` של כל וקטור\n","- באמצעות כלל השרשרת עושה את התהליך הזה כל הדרך עד העלים (שהם ה_input_) \n","\n","בתמונה להלן תרשים של עץ _autograd_ פשוט,  \n","החיצים מסמנים את תהליך ה_forward_ שזה תהליך החישוב של הפונקציות בNN, \n","הצמתים בעץ מייצגים את אובייקטי הפונקציות של כל חישוב שנעשה עד שהגענו לתוצאה \n","העלים הם הקלט של הפונקציה עלהם עשינו את כל החישובים. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","a = torch.tensor([2., 3.], requires_grad=True)\n","b = torch.tensor([6., 4.], requires_grad=True)\n","Q = 3*a**3 - b**2\n","external_grad = torch.tensor([1., 1.])\n","Q.backward(gradient=external_grad)"]},{"cell_type":"markdown","metadata":{},"source":["![image-2.png](attachment:image-2.png)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n",">💡 עץ הפונקציות של _autograd_ נוצר מחדש בכל קריאה של `()backward.` כך אפשר לשנות את הפעולת בכל ריצה.  \n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","### הקפאת פרמטרים _frozen parameters_  \n","\n","_autograd_ עוקב אחרי כל הטנזורים שהמאפיין `requires_grad.` שלהם מסומן כ`True`. לפעמים יש טנזורים שלא נרצה לחשב להם את הגרדיאנט (ולשנות אותם) בשביל זה אפשר לשנות את הערך ל`False`\n","\n","כאשר יוצרים טנזורים באופן דיפולטיבי הם `.requires_grad=False` ניתן לשנות זאת במופרש כשמגדירים אותם. \n","כאשר יוצרים טנזורים מטנזורים אחרים ע\"י פעולות מתמטיות, דיי בכך שטנזור אחד מאלה המרכיבים אותו יהיה  `.requires_grad=True` בשביל שהטנזור שנוצר יהיה ג\"כ `.requires_grad=True` "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Does `a` require gradients? : False\n","Does `b` require gradients?: True\n"]}],"source":["x = torch.rand(5, 5)\n","y = torch.rand(5, 5)\n","z = torch.rand((5, 5), requires_grad=True)\n","\n","a = x + y\n","print(f\"Does `a` require gradients? : {a.requires_grad}\")\n","b = x + z\n","print(f\"Does `b` require gradients?: {b.requires_grad}\")"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","ברשתות נויירונים _NN_ פרמטרים שלא מחשבים להם את הגרדיאנט נקראים \"פרמטרים קפואים\" _frozen parameters_. זה שימושי \"להקפיא\" חלק מהפרמטרים בשביל לשפר את ביצועי המחשב. "]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","### אימון משני _finetuning_\n","עוד סיבה נפוצה לא לכלול פרמטרים ב_autograd_ היא בשביל הכללת ידע - כלומר לקיחת רשת נויירונים שעובדת ושינוי של חלק מהשכבות שבה למטרה אחרת  [_finetuning_](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)\n","[הכללת ידע](https://www.ai-blog.co.il/2018/12/16/transfer-learning-%D7%94%D7%9B%D7%9C%D7%9C%D7%AA-%D7%99%D7%93%D7%A2/)\n","\n","\n","בדוגמה להלן נקח את המודל _resnet18_ שכמו שכתבנו לעיל הוא מאומן על זיהוי תמונות ונקפיא את כל הפרמטרים שלו \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import nn, optim\n","\n","model = torchvision.models.resnet18(pretrained=True)\n","\n","# Freeze all the parameters in the network\n","for param in model.parameters():\n","    param.requires_grad = False"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","נניח שאנחנו רוצים להשתמש במודל _resnet_ בשביל דאטה בייס אחר , עם עשר שכבות?. במודל מסוג כזה השכבה האחרונה שנמצאת ב`model.fc`  היא שיכבה ליניארית והיא זאת שנותנת לכל קלט את התשובה הסופית. כלומר היא מהווה _classifier_. אם נרצה לאמן את המודל שלנו על סוג אתר של דאטא. נוכל להחליף את השיכבה הזאת בשיכבה חדשה שתמיין את התמונה לפי הצרכים שלנו.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fc = nn.Linear(512, 10)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","כעת כל השכבות מוקפאות, להוציא את השיכבה האחרונה `model.fc`, לכן תהליך האימון ישנה רק את הפרמטרים בשיכבה האחרונה. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Optimize only the classifier\n","optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","ניתן לשים לב שלמרות שהכניסו לתוך פונצקיית האופטימיזציה את כל המודל, הפרמטרים היחידים שישונו הם אלה של השיכבה האחרונה שלא הוקפאה.\n","\n","בצורה מעט שונה ניתן להקפיא פרמטרים ע\"י `:()with torch.no_grad` יש עוד פירוט \n","[פה](https://pytorch.org/docs/stable/generated/torch.no_grad.html) \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","### לקריאה נוספת\n","\n","\n","-  הסבר מפורט על _autograd_ ושימוש מתקדם בו \n","[Autograd Mechanics](https://pytorch.org/docs/stable/notes/autograd.html)\n","-  הדגמה לשימוש ב_autograd_ בצורה אינטראקטיבית \n","[Simple Grad](https://colab.research.google.com/drive/1VpeE6UvEPRz9HmsHh1KS0XxXjYu533EC)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","המחברת הזו היא תרגום של המחברת \n","[הזו](https://colab.research.google.com/drive/1aWNdmYt7RcHMbUk-Xz2Cv5-cGFSWPXe0#scrollTo=WIanlOJ_67pf)\n","# מטרה\n","\n","* להבין איך עובד תהליך ה\n","_backpropagation_ \n","ב\n","_pytorch_\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","# הכנות"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchviz\n","  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchviz) (1.13.0+cu116)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from torchviz) (0.10.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchviz) (4.4.0)\n","Building wheels for collected packages: torchviz\n","  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4151 sha256=d8b5cfad497f08252cec25af5130413185e6646107b095562908ab6cb01e0070\n","  Stored in directory: /root/.cache/pip/wheels/05/7d/1b/8306781244e42ede119edbb053bdcda1c1f424ca226165a417\n","Successfully built torchviz\n","Installing collected packages: torchviz\n","Successfully installed torchviz-0.0.2\n"]}],"source":["\n","!pip install torchviz\n"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","# הדגמה פשוטה על ריגריסה ליניארית"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","אנו מעוניינים למצוא את הוקטור \n","$x$ \n","שפותר את המשוואה\n","$Ax+b = t$\n","במקרה שלנו הפתרון יהיה \n","$x=()\n","\n","??\n","We want to learn A and B such that t = Ax + B, (solution for our data is A = 2, B = 3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","x = torch.tensor([1., 2.])\n","t = torch.tensor([5., 7.])"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","נשים ערכים אקראים כל שהם ב\n","$x$  \n","וב\n","$y$  \n","כמובן שערכים אלו לא יתנו לנו טובה, אותם נוכל לשפר בתהליך האימון עד שנמצא ערכים נכונים"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["A = torch.tensor([3.], requires_grad=True)\n","B = torch.tensor([5.], requires_grad=True)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","נבנה את המודל שלנו"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def model(x):\n","    scaled = A * x\n","    return scaled + B"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","נגדיר פונקציית שגיאה\n","_loss function_\n","כך נעריך כמה מה שהמודל שלנו חזה רחוק מהתשובה הנכונה. \n","זהו מודל שגיאה ריבועי והוא מחזיר את ריבוע ההפרש "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def loss_fn(y, t):\n","    diff = y - t\n","    sqdiff = diff ** 2\n","    return sqdiff.sum()"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","נבנה פונקציית אופטימיזציה - כלומר פונקציה שמעדכנת את \n","$A$ \n","ו\n","$b$ \n","כך שהתוצאה תהיה קמה שיותר קרובה. \n","נחשב את הגרדיאנט של \n","$A$ \n","ו\n","$b$ \n","ונעדכן את הערכים שלהם בתהליך הגרדיאנט דסנט\n","\n","ניתן לשים לב שאנחנו מניחים שהמאפיין\n"," ```.grad```\n","מעודכן לכל טנסור בערכים הנכונים לו"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sgd_step(lr=0.1):\n","    global A\n","    global B\n","    with torch.no_grad(): \n","        A -= A.grad * lr \n","        A.grad.zero_()\n","        B -= B.grad * lr\n","        B.grad.zero_()"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","\n","כעת ניתן לאמן את המודל שלנו!!\n","תכלו להריץ את הקוד מספר פעמים ולראות כיצד אנחנו מקבלים את הערכים הנכונים"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loss: 25.0, A: 0.7999999523162842, B: 3.5999999046325684\n","loss: 0.0005399102228693664, A: 1.9689515829086304, B: 3.0502371788024902\n","loss: 1.445937641619821e-06, A: 1.9983934164047241, B: 3.0025997161865234\n","loss: 3.852846930385567e-09, A: 1.9999167919158936, B: 3.0001344680786133\n","loss: 1.0231815394945443e-11, A: 1.9999959468841553, B: 3.0000064373016357\n","loss: 1.1368683772161603e-12, A: 1.9999983310699463, B: 3.000002861022949\n","loss: 1.1368683772161603e-12, A: 1.9999983310699463, B: 3.000002861022949\n","loss: 1.1368683772161603e-12, A: 1.9999983310699463, B: 3.000002861022949\n","loss: 1.1368683772161603e-12, A: 1.9999983310699463, B: 3.000002861022949\n","loss: 1.1368683772161603e-12, A: 1.9999983310699463, B: 3.000002861022949\n"]}],"source":["for i in range(1000):\n","    y = model(x)\n","    loss = loss_fn(y, t)\n","    loss.backward()\n","    sgd_step()\n","    if i % 100 == 0:\n","      print(\"loss: {}, A: {}, B: {}\".format(loss, A.item(), B.item()))"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","# חישוב הגרדיאנט בצורה ידנית\n","גרדינאט דסנט הוא תהליך שמצמצם את ההפרש בן ערך הפונקציה בנקודה מסויימת לבן ערך המטרה - הערך אותו אנחנו רוצים לקבל, בתהליך אנחנו משנים הפרמטרים של הפונקציה (\n","  $A$ \n","  ו\n","  $b$ \n","  במקרה שלנו)\n","  ביחס לשיעור השגיאה \n","\n","אנחנו יודעים כמה לשנות בפרמטרים של הפונקציה ע\"י חישוב הגרדיאנט שהיא פונקציית הנגזרת החלקית. \n","במקרה שלנו נרצה לחשב \n","$\\frac{\\partial loss}{\\partial A}, \\frac{\\partial loss}{\\partial B}$."]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","בשביל לחשב את הנגזרת החלקית עלינו להתשמש בכלל השרשרת, החל מערך ההפסד עד \n","\n","$ \\frac{\\partial loss}{\\partial A} = \\sum_i \\frac{\\partial loss}{\\partial sqdiff_i} * \\frac{\\partial sqdiff_i}{\\partial A}$ (applied chain rule once)\n","\n","$= \\sum_i \\frac{\\partial loss}{\\partial sqdiff_i} * \\frac{\\partial sqdiff_i}{\\partial diff_i} * \\frac{\\partial diff_i}{\\partial A}$\n","\n","$= \\sum_i \\frac{\\partial loss}{\\partial sqdiff_i} * \\frac{\\partial sqdiff_i}{\\partial diff_i} * \\frac{\\partial diff_i}{\\partial y_i} * \\frac{\\partial y_i}{\\partial scaled_i} * \\frac{\\partial scaled_i}{\\partial A}$ (keep applying chain rule)"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","Now, we (the authors of the model code) know the derivatives formulas for some of these, by reading the code. Shortening the above model code into the following, we can replace some of the partial derivatives above:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# As a reminder, here's what our code looked like\n","import torch\n","x = torch.tensor([1., 2.])\n","t = torch.tensor([5., 7.])\n","A = torch.tensor([3.], requires_grad=True)\n","B = torch.tensor([5.], requires_grad=True)\n","\n","# Forward\n","scaled = A * x\n","y= scaled + B\n","diff = y - t\n","sqdiff =  diff ** 2\n","loss = sqdiff.sum()"]},{"cell_type":"markdown","metadata":{},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n","\n","Things we know:\n","$$ \\frac{\\partial loss}{\\partial sqdiff_i} = 1$$\n","\n","$$ \\frac{\\partial sqdiff_i}{\\partial diff_i} = 2 * diff_i$$\n","\n","$$ \\frac{\\partial diff_i}{\\partial y_i} = 1 $$\n","\n","$$ \\frac{\\partial y_i}{\\partial scaled_i} = 1 $$\n","\n","$$ \\frac{\\partial scaled_i}{\\partial A} = x_i $$"]},{"cell_type":"markdown","metadata":{},"source":["Plugging everything back in, we get:\n","\n","$$ \\frac{\\partial loss}{\\partial A} = \\sum_i 2 * diff_i * x_i$$\n","\n","Let's verify our math really quickly:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# backward\n","grad_A = (diff * 2 * x).sum()\n","expected, = torch.autograd.grad(loss, A, retain_graph=True)\n","assert torch.allclose(grad_A, expected)"]},{"cell_type":"markdown","metadata":{},"source":["Awesome, everything works out! **As an exercise, the numeric computation of grad_B is left to the reader.**\n","After deriving for B, we get the following:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# backward\n","diff_2 = diff * 2\n","grad_A = (diff_2 * x).sum()\n","grad_B = diff_2.sum()\n","expected = torch.autograd.grad(loss, [A, B], retain_graph=True)\n","assert torch.allclose(grad_A, expected[0])\n","assert torch.allclose(grad_B, expected[1])"]},{"cell_type":"markdown","metadata":{},"source":["# Here’s how PyTorch’s autograd does it\n","\n","During the forward pass, autograd builds up a computation graph eagerly. This computation graph is represented with Nodes and Edges. \n","\n","* Whenever an operation is called on a tensor that requires grad (e.g., mul), PyTorch creates a Node in the computation graph\n","* A Node can store a reference to Tensors and other things that it needs for backward computation (we’ll see an example of this later)\n","* When it comes time to compute gradients, we pass some values through the created autograd graph.\n","* Each node defines a backward formula.\n","\n","Here’s a concrete example, using the above code.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","x = torch.tensor([1., 2.])\n","t = torch.tensor([5., 7.])\n","A = torch.tensor([3.], requires_grad=True)\n","B = torch.tensor([5.], requires_grad=True)\n","\n","# Forward\n","scaled = A * x\n","y= scaled + B\n","diff = y - t\n","sqdiff =  diff ** 2\n","loss = sqdiff.sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n"," -->\n","<!-- Title: %3 Pages: 1 -->\n","<svg width=\"62pt\" height=\"38pt\"\n"," viewBox=\"0.00 0.00 62.00 38.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 34)\">\n","<title>%3</title>\n","<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-34 58,-34 58,4 -4,4\"/>\n","<!-- 140602457417344 -->\n","<g id=\"node1\" class=\"node\">\n","<title>140602457417344</title>\n","<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"54,-30 0,-30 0,0 54,0 54,-30\"/>\n","<text text-anchor=\"middle\" x=\"27\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">A</text>\n","<text text-anchor=\"middle\" x=\"27\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.dot.Digraph at 0x7fe08edc72e0>"]},"metadata":{},"output_type":"display_data"}],"source":["import torchviz\n","\n","# Please run this in PyTorch >= 1.9\n","torchviz.make_dot(A, params={'A': A, 'B': B},show_attrs=True)"]},{"cell_type":"markdown","metadata":{},"source":["```\n","  import torch\n","  x = torch.tensor([1., 2.])\n","  t = torch.tensor([5., 7.])\n","  A = torch.tensor([3.], requires_grad=True)\n","  B = torch.tensor([5.], requires_grad=True)\n"," \n","  # Forward\n","> scaled = A * x\n","  y= scaled + B\n","  diff = y - t\n","  sqdiff = diff ** 2\n","  loss = sqdiff.sum()\n","```\n","\n","Note that MulBackward0 saves the tensor `x` as the \"other\" tensor.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n"," -->\n","<!-- Title: %3 Pages: 1 -->\n","<svg width=\"151pt\" height=\"247pt\"\n"," viewBox=\"0.00 0.00 151.00 247.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 243)\">\n","<title>%3</title>\n","<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-243 147,-243 147,4 -4,4\"/>\n","<!-- 140602457417584 -->\n","<g id=\"node1\" class=\"node\">\n","<title>140602457417584</title>\n","<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"98.5,-30 44.5,-30 44.5,0 98.5,0 98.5,-30\"/>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">S</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (2)</text>\n","</g>\n","<!-- 140602446215200 -->\n","<g id=\"node2\" class=\"node\">\n","<title>140602446215200</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"143,-118 0,-118 0,-66 143,-66 143,-118\"/>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-106\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n","</g>\n","<!-- 140602446215200&#45;&gt;140602457417584 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>140602446215200&#45;&gt;140602457417584</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M71.5,-65.9313C71.5,-57.6799 71.5,-48.575 71.5,-40.3731\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.0001,-40.2587 71.5,-30.2587 68.0001,-40.2588 75.0001,-40.2587\"/>\n","</g>\n","<!-- 140602446215056 -->\n","<g id=\"node3\" class=\"node\">\n","<title>140602446215056</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"122,-173 21,-173 21,-154 122,-154 122,-173\"/>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 140602446215056&#45;&gt;140602446215200 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>140602446215056&#45;&gt;140602446215200</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M71.5,-153.8572C71.5,-147.1389 71.5,-137.7159 71.5,-128.2465\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.0001,-128.0786 71.5,-118.0787 68.0001,-128.0787 75.0001,-128.0786\"/>\n","</g>\n","<!-- 140602457417344 -->\n","<g id=\"node4\" class=\"node\">\n","<title>140602457417344</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"98.5,-239 44.5,-239 44.5,-209 98.5,-209 98.5,-239\"/>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">A</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-216\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 140602457417344&#45;&gt;140602446215056 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>140602457417344&#45;&gt;140602446215056</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M71.5,-208.7333C71.5,-201.0322 71.5,-191.5977 71.5,-183.3414\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.0001,-183.0864 71.5,-173.0864 68.0001,-183.0864 75.0001,-183.0864\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.dot.Digraph at 0x7fe08edaa0d0>"]},"metadata":{},"output_type":"display_data"}],"source":["torchviz.make_dot(scaled, params={'A': A, 'S':scaled , 'X':x},show_attrs=True)"]},{"cell_type":"markdown","metadata":{},"source":["What is this AccumulateGrad Node?\n","\n","Every leaf Tensor that requires gradient gets an AccumulateGrad Node associated with it. That Node is used to link back to the Tensor and know on which Tensor the gradients should be accumulated.\n","Note that the AccumulateGrad Nodes are the *only* Nodes that do not have parents pointing to them."]},{"cell_type":"markdown","metadata":{},"source":["```\n","  import torch\n","  x = torch.tensor([1., 2.])\n","  t = torch.tensor([5., 7.])\n","  A = torch.tensor([3.], requires_grad=True)\n","  B = torch.tensor([5.], requires_grad=True)\n"," \n","  # Forward\n","  scaled = A * x\n","> y= scaled + B\n","  diff = y - t\n","  sqdiff = diff ** 2\n","  loss = sqdiff.sum()\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n"," -->\n","<!-- Title: %3 Pages: 1 -->\n","<svg width=\"222pt\" height=\"280pt\"\n"," viewBox=\"0.00 0.00 222.00 280.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 276)\">\n","<title>%3</title>\n","<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-276 218,-276 218,4 -4,4\"/>\n","<!-- 140602457417664 -->\n","<g id=\"node1\" class=\"node\">\n","<title>140602457417664</title>\n","<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"145,-30 68,-30 68,0 145,0 145,-30\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">The tensor</text>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (2)</text>\n","</g>\n","<!-- 140602446213664 -->\n","<g id=\"node2\" class=\"node\">\n","<title>140602446213664</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-85 62,-85 62,-66 151,-66 151,-85\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n","</g>\n","<!-- 140602446213664&#45;&gt;140602457417664 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>140602446213664&#45;&gt;140602457417664</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-65.7796C106.5,-58.8654 106.5,-49.2417 106.5,-40.2296\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-40.1301 106.5,-30.1301 103.0001,-40.1302 110.0001,-40.1301\"/>\n","</g>\n","<!-- 140602446214432 -->\n","<g id=\"node3\" class=\"node\">\n","<title>140602446214432</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-140 6,-140 6,-121 95,-121 95,-140\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-128\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n","</g>\n","<!-- 140602446214432&#45;&gt;140602446213664 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>140602446214432&#45;&gt;140602446213664</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M60.2545,-120.9197C68.1865,-113.1293 79.5788,-101.9405 89.0712,-92.6176\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.7982,-94.845 96.4802,-85.3408 86.8932,-89.8509 91.7982,-94.845\"/>\n","</g>\n","<!-- 140602446216592 -->\n","<g id=\"node4\" class=\"node\">\n","<title>140602446216592</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-200.5 0,-200.5 0,-181.5 101,-181.5 101,-200.5\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-188.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 140602446216592&#45;&gt;140602446214432 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>140602446216592&#45;&gt;140602446214432</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-181.2796C50.5,-173.0376 50.5,-160.9457 50.5,-150.629\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-150.3972 50.5,-140.3972 47.0001,-150.3973 54.0001,-150.3972\"/>\n","</g>\n","<!-- 140602457417344 -->\n","<g id=\"node5\" class=\"node\">\n","<title>140602457417344</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-272 23.5,-272 23.5,-242 77.5,-242 77.5,-272\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-260\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">A</text>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 140602457417344&#45;&gt;140602446216592 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>140602457417344&#45;&gt;140602446216592</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-241.6924C50.5,-232.5067 50.5,-220.7245 50.5,-210.8312\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-210.703 50.5,-200.7031 47.0001,-210.7031 54.0001,-210.703\"/>\n","</g>\n","<!-- 140602446214864 -->\n","<g id=\"node6\" class=\"node\">\n","<title>140602446214864</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-140 113,-140 113,-121 214,-121 214,-140\"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-128\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 140602446214864&#45;&gt;140602446213664 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>140602446214864&#45;&gt;140602446213664</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M153.5714,-120.9197C145.4169,-113.0514 133.6697,-101.7164 123.9508,-92.3385\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3252,-89.7659 116.6987,-85.3408 121.4646,-94.8032 126.3252,-89.7659\"/>\n","</g>\n","<!-- 140602457417424 -->\n","<g id=\"node7\" class=\"node\">\n","<title>140602457417424</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"190.5,-206 136.5,-206 136.5,-176 190.5,-176 190.5,-206\"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-194\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">B</text>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-183\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 140602457417424&#45;&gt;140602446214864 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>140602457417424&#45;&gt;140602446214864</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-175.7333C163.5,-168.0322 163.5,-158.5977 163.5,-150.3414\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-150.0864 163.5,-140.0864 160.0001,-150.0864 167.0001,-150.0864\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.dot.Digraph at 0x7fe08ed74e50>"]},"metadata":{},"output_type":"display_data"}],"source":["torchviz.make_dot(y, params={'A': A, 'B': B,'s':scaled,'The tensor':y})"]},{"cell_type":"markdown","metadata":{},"source":["```\n","  import torch\n","  x = torch.tensor([1., 2.])\n","  t = torch.tensor([5., 7.])\n","  A = torch.tensor([3.], requires_grad=True)\n","  B = torch.tensor([5.], requires_grad=True)\n"," \n","  # Forward\n","  scaled = A * x\n","  y= scaled + B\n","> diff = y - t\n","  sqdiff = diff ** 2\n","  loss = sqdiff.sum()\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n"," -->\n","<!-- Title: %3 Pages: 1 -->\n","<svg width=\"222pt\" height=\"336pt\"\n"," viewBox=\"0.00 0.00 222.00 336.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 332)\">\n","<title>%3</title>\n","<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-332 218,-332 218,4 -4,4\"/>\n","<!-- 139683924708640 -->\n","<g id=\"node1\" class=\"node\">\n","<title>139683924708640</title>\n","<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (2)</text>\n","</g>\n","<!-- 139683924358544 -->\n","<g id=\"node2\" class=\"node\">\n","<title>139683924358544</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n","</g>\n","<!-- 139683924358544&#45;&gt;139683924708640 -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>139683924358544&#45;&gt;139683924708640</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-66.9688C106.5,-60.1289 106.5,-50.5621 106.5,-41.5298\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-41.3678 106.5,-31.3678 103.0001,-41.3678 110.0001,-41.3678\"/>\n","</g>\n","<!-- 139683924715536 -->\n","<g id=\"node3\" class=\"node\">\n","<title>139683924715536</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n","</g>\n","<!-- 139683924715536&#45;&gt;139683924358544 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>139683924715536&#45;&gt;139683924358544</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-121.9197C106.5,-114.9083 106.5,-105.1442 106.5,-96.4652\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-96.3408 106.5,-86.3408 103.0001,-96.3409 110.0001,-96.3408\"/>\n","</g>\n","<!-- 139683924714128 -->\n","<g id=\"node4\" class=\"node\">\n","<title>139683924714128</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n","</g>\n","<!-- 139683924714128&#45;&gt;139683924715536 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>139683924714128&#45;&gt;139683924715536</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M60.2545,-176.9197C68.1865,-169.1293 79.5788,-157.9405 89.0712,-148.6176\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.7982,-150.845 96.4802,-141.3408 86.8932,-145.8509 91.7982,-150.845\"/>\n","</g>\n","<!-- 139683924357584 -->\n","<g id=\"node5\" class=\"node\">\n","<title>139683924357584</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-256.5 0,-256.5 0,-237.5 101,-237.5 101,-256.5\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-244.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 139683924357584&#45;&gt;139683924714128 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>139683924357584&#45;&gt;139683924714128</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-237.2796C50.5,-229.0376 50.5,-216.9457 50.5,-206.629\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-206.3972 50.5,-196.3972 47.0001,-206.3973 54.0001,-206.3972\"/>\n","</g>\n","<!-- 139685465354144 -->\n","<g id=\"node6\" class=\"node\">\n","<title>139685465354144</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-328 23.5,-328 23.5,-298 77.5,-298 77.5,-328\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">A</text>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 139685465354144&#45;&gt;139683924357584 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>139685465354144&#45;&gt;139683924357584</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-297.6924C50.5,-288.5067 50.5,-276.7245 50.5,-266.8312\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-266.703 50.5,-256.7031 47.0001,-266.7031 54.0001,-266.703\"/>\n","</g>\n","<!-- 139683924713744 -->\n","<g id=\"node7\" class=\"node\">\n","<title>139683924713744</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-196 113,-196 113,-177 214,-177 214,-196\"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 139683924713744&#45;&gt;139683924715536 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>139683924713744&#45;&gt;139683924715536</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M153.5714,-176.9197C145.4169,-169.0514 133.6697,-157.7164 123.9508,-148.3385\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3252,-145.7659 116.6987,-141.3408 121.4646,-150.8032 126.3252,-145.7659\"/>\n","</g>\n","<!-- 139683924708960 -->\n","<g id=\"node8\" class=\"node\">\n","<title>139683924708960</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"190.5,-262 136.5,-262 136.5,-232 190.5,-232 190.5,-262\"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">B</text>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 139683924708960&#45;&gt;139683924713744 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>139683924708960&#45;&gt;139683924713744</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-231.7333C163.5,-224.0322 163.5,-214.5977 163.5,-206.3414\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-206.0864 163.5,-196.0864 160.0001,-206.0864 167.0001,-206.0864\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.dot.Digraph at 0x7f0ab2b13e90>"]},"metadata":{},"output_type":"display_data"}],"source":["torchviz.make_dot(diff, params={'A': A, 'B': B})"]},{"cell_type":"markdown","metadata":{},"source":["```\n","  import torch\n","  x = torch.tensor([1., 2.])\n","  t = torch.tensor([5., 7.])\n","  A = torch.tensor([3.], requires_grad=True)\n","  B = torch.tensor([5.], requires_grad=True)\n"," \n","  # Forward\n","  scaled = A * x\n","  y= scaled + B\n","  diff = y - t\n","> sqdiff = diff ** 2\n","  loss = sqdiff.sum()\n","```\n","Note that `self` being saved by PowBackward is `diff`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n"," -->\n","<!-- Title: %3 Pages: 1 -->\n","<svg width=\"222pt\" height=\"391pt\"\n"," viewBox=\"0.00 0.00 222.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n","<title>%3</title>\n","<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-387 218,-387 218,4 -4,4\"/>\n","<!-- 139683924706400 -->\n","<g id=\"node1\" class=\"node\">\n","<title>139683924706400</title>\n","<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (2)</text>\n","</g>\n","<!-- 139683924360976 -->\n","<g id=\"node2\" class=\"node\">\n","<title>139683924360976</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n","</g>\n","<!-- 139683924360976&#45;&gt;139683924706400 -->\n","<g id=\"edge8\" class=\"edge\">\n","<title>139683924360976&#45;&gt;139683924706400</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-66.9688C106.5,-60.1289 106.5,-50.5621 106.5,-41.5298\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-41.3678 106.5,-31.3678 103.0001,-41.3678 110.0001,-41.3678\"/>\n","</g>\n","<!-- 139683924358544 -->\n","<g id=\"node3\" class=\"node\">\n","<title>139683924358544</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n","</g>\n","<!-- 139683924358544&#45;&gt;139683924360976 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>139683924358544&#45;&gt;139683924360976</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-121.9197C106.5,-114.9083 106.5,-105.1442 106.5,-96.4652\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-96.3408 106.5,-86.3408 103.0001,-96.3409 110.0001,-96.3408\"/>\n","</g>\n","<!-- 139683924715536 -->\n","<g id=\"node4\" class=\"node\">\n","<title>139683924715536</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-196 62,-196 62,-177 151,-177 151,-196\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n","</g>\n","<!-- 139683924715536&#45;&gt;139683924358544 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>139683924715536&#45;&gt;139683924358544</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-176.9197C106.5,-169.9083 106.5,-160.1442 106.5,-151.4652\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-151.3408 106.5,-141.3408 103.0001,-151.3409 110.0001,-151.3408\"/>\n","</g>\n","<!-- 139683924714128 -->\n","<g id=\"node5\" class=\"node\">\n","<title>139683924714128</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-251 6,-251 6,-232 95,-232 95,-251\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n","</g>\n","<!-- 139683924714128&#45;&gt;139683924715536 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>139683924714128&#45;&gt;139683924715536</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M60.2545,-231.9197C68.1865,-224.1293 79.5788,-212.9405 89.0712,-203.6176\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.7982,-205.845 96.4802,-196.3408 86.8932,-200.8509 91.7982,-205.845\"/>\n","</g>\n","<!-- 139683924357584 -->\n","<g id=\"node6\" class=\"node\">\n","<title>139683924357584</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-311.5 0,-311.5 0,-292.5 101,-292.5 101,-311.5\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-299.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 139683924357584&#45;&gt;139683924714128 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>139683924357584&#45;&gt;139683924714128</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-292.2796C50.5,-284.0376 50.5,-271.9457 50.5,-261.629\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-261.3972 50.5,-251.3972 47.0001,-261.3973 54.0001,-261.3972\"/>\n","</g>\n","<!-- 139685465354144 -->\n","<g id=\"node7\" class=\"node\">\n","<title>139685465354144</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-383 23.5,-383 23.5,-353 77.5,-353 77.5,-383\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">A</text>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 139685465354144&#45;&gt;139683924357584 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>139685465354144&#45;&gt;139683924357584</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-352.6924C50.5,-343.5067 50.5,-331.7245 50.5,-321.8312\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-321.703 50.5,-311.7031 47.0001,-321.7031 54.0001,-321.703\"/>\n","</g>\n","<!-- 139683924713744 -->\n","<g id=\"node8\" class=\"node\">\n","<title>139683924713744</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-251 113,-251 113,-232 214,-232 214,-251\"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 139683924713744&#45;&gt;139683924715536 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>139683924713744&#45;&gt;139683924715536</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M153.5714,-231.9197C145.4169,-224.0514 133.6697,-212.7164 123.9508,-203.3385\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3252,-200.7659 116.6987,-196.3408 121.4646,-205.8032 126.3252,-200.7659\"/>\n","</g>\n","<!-- 139683924708960 -->\n","<g id=\"node9\" class=\"node\">\n","<title>139683924708960</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"190.5,-317 136.5,-317 136.5,-287 190.5,-287 190.5,-317\"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">B</text>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 139683924708960&#45;&gt;139683924713744 -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>139683924708960&#45;&gt;139683924713744</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-286.7333C163.5,-279.0322 163.5,-269.5977 163.5,-261.3414\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-261.0864 163.5,-251.0864 160.0001,-261.0864 167.0001,-261.0864\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.dot.Digraph at 0x7f0ab2b17b50>"]},"metadata":{},"output_type":"display_data"}],"source":["torchviz.make_dot(sqdiff, params={'A': A, 'B': B})"]},{"cell_type":"markdown","metadata":{},"source":["```\n","  import torch\n","  x = torch.tensor([1., 2.])\n","  t = torch.tensor([5., 7.])\n","  A = torch.tensor([3.], requires_grad=True)\n","  B = torch.tensor([5.], requires_grad=True)\n"," \n","  # Forward\n","  scaled = A * x\n","  y= scaled + B\n","  diff = y - t\n","  sqdiff = diff ** 2\n","> loss = sqdiff.sum()\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n"," -->\n","<!-- Title: %3 Pages: 1 -->\n","<svg width=\"222pt\" height=\"446pt\"\n"," viewBox=\"0.00 0.00 222.00 446.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 442)\">\n","<title>%3</title>\n","<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-442 218,-442 218,4 -4,4\"/>\n","<!-- 139683924729520 -->\n","<g id=\"node1\" class=\"node\">\n","<title>139683924729520</title>\n","<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> ()</text>\n","</g>\n","<!-- 139683924377040 -->\n","<g id=\"node2\" class=\"node\">\n","<title>139683924377040</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SumBackward0</text>\n","</g>\n","<!-- 139683924377040&#45;&gt;139683924729520 -->\n","<g id=\"edge9\" class=\"edge\">\n","<title>139683924377040&#45;&gt;139683924729520</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-66.9688C106.5,-60.1289 106.5,-50.5621 106.5,-41.5298\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-41.3678 106.5,-31.3678 103.0001,-41.3678 110.0001,-41.3678\"/>\n","</g>\n","<!-- 139683924360976 -->\n","<g id=\"node3\" class=\"node\">\n","<title>139683924360976</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n","</g>\n","<!-- 139683924360976&#45;&gt;139683924377040 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>139683924360976&#45;&gt;139683924377040</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-121.9197C106.5,-114.9083 106.5,-105.1442 106.5,-96.4652\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-96.3408 106.5,-86.3408 103.0001,-96.3409 110.0001,-96.3408\"/>\n","</g>\n","<!-- 139683924358544 -->\n","<g id=\"node4\" class=\"node\">\n","<title>139683924358544</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-196 62,-196 62,-177 151,-177 151,-196\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n","</g>\n","<!-- 139683924358544&#45;&gt;139683924360976 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>139683924358544&#45;&gt;139683924360976</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-176.9197C106.5,-169.9083 106.5,-160.1442 106.5,-151.4652\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-151.3408 106.5,-141.3408 103.0001,-151.3409 110.0001,-151.3408\"/>\n","</g>\n","<!-- 139683924715536 -->\n","<g id=\"node5\" class=\"node\">\n","<title>139683924715536</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-251 62,-251 62,-232 151,-232 151,-251\"/>\n","<text text-anchor=\"middle\" x=\"106.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n","</g>\n","<!-- 139683924715536&#45;&gt;139683924358544 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>139683924715536&#45;&gt;139683924358544</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-231.9197C106.5,-224.9083 106.5,-215.1442 106.5,-206.4652\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-206.3408 106.5,-196.3408 103.0001,-206.3409 110.0001,-206.3408\"/>\n","</g>\n","<!-- 139683924714128 -->\n","<g id=\"node6\" class=\"node\">\n","<title>139683924714128</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"95,-306 6,-306 6,-287 95,-287 95,-306\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n","</g>\n","<!-- 139683924714128&#45;&gt;139683924715536 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>139683924714128&#45;&gt;139683924715536</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M60.2545,-286.9197C68.1865,-279.1293 79.5788,-267.9405 89.0712,-258.6176\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.7982,-260.845 96.4802,-251.3408 86.8932,-255.8509 91.7982,-260.845\"/>\n","</g>\n","<!-- 139683924357584 -->\n","<g id=\"node7\" class=\"node\">\n","<title>139683924357584</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-366.5 0,-366.5 0,-347.5 101,-347.5 101,-366.5\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-354.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 139683924357584&#45;&gt;139683924714128 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>139683924357584&#45;&gt;139683924714128</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-347.2796C50.5,-339.0376 50.5,-326.9457 50.5,-316.629\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-316.3972 50.5,-306.3972 47.0001,-316.3973 54.0001,-316.3972\"/>\n","</g>\n","<!-- 139685465354144 -->\n","<g id=\"node8\" class=\"node\">\n","<title>139685465354144</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-438 23.5,-438 23.5,-408 77.5,-408 77.5,-438\"/>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">A</text>\n","<text text-anchor=\"middle\" x=\"50.5\" y=\"-415\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 139685465354144&#45;&gt;139683924357584 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>139685465354144&#45;&gt;139683924357584</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-407.6924C50.5,-398.5067 50.5,-386.7245 50.5,-376.8312\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-376.703 50.5,-366.7031 47.0001,-376.7031 54.0001,-376.703\"/>\n","</g>\n","<!-- 139683924713744 -->\n","<g id=\"node9\" class=\"node\">\n","<title>139683924713744</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-306 113,-306 113,-287 214,-287 214,-306\"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 139683924713744&#45;&gt;139683924715536 -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>139683924713744&#45;&gt;139683924715536</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M153.5714,-286.9197C145.4169,-279.0514 133.6697,-267.7164 123.9508,-258.3385\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3252,-255.7659 116.6987,-251.3408 121.4646,-260.8032 126.3252,-255.7659\"/>\n","</g>\n","<!-- 139683924708960 -->\n","<g id=\"node10\" class=\"node\">\n","<title>139683924708960</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"190.5,-372 136.5,-372 136.5,-342 190.5,-342 190.5,-372\"/>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">B</text>\n","<text text-anchor=\"middle\" x=\"163.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 139683924708960&#45;&gt;139683924713744 -->\n","<g id=\"edge8\" class=\"edge\">\n","<title>139683924708960&#45;&gt;139683924713744</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-341.7333C163.5,-334.0322 163.5,-324.5977 163.5,-316.3414\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-316.0864 163.5,-306.0864 160.0001,-316.0864 167.0001,-316.0864\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.dot.Digraph at 0x7f0ab2b1b890>"]},"metadata":{},"output_type":"display_data"}],"source":["torchviz.make_dot(loss, params={'A': A, 'B': B, 'x': x, 'diff': diff})"]},{"cell_type":"markdown","metadata":{},"source":["`loss.backward()` invokes a series of operations on this graph. In Pseudocode:\n","```\n","grad_sqdiff = SumBackward(sqdiff.shape).apply(1.)\n","grad_diff = PowBackward(base: diff, power: 2).apply(grad_sqdiff)\n","grad_y = SubBackward().apply(grad_diff)\n","grad_scaled, grad_B = AddBackward().apply(grad_y)\n","grad_A = MulBackward(other: X).apply(grad_scaled)\n","```\n","`SumBackward(input_shape).apply(grad)` is `grad.expand(input_shape)`.\n","\n","`PowBackward(base, power).apply(grad)` is `grad * power * base ** (power - 1)`. \n","\n","And so on...\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grad_sqdiff = torch.tensor(1.).expand(sqdiff.shape)\n","grad_diff = grad_sqdiff * 2 * diff\n","grad_y = grad_diff\n","grad_scaled, grad_B = grad_y, grad_y.sum()\n","grad_A = (grad_scaled * x).sum()"]},{"cell_type":"markdown","metadata":{},"source":["There are two things to discuss here:\n","\n","* How exactly are the grad formula derived?\n","    * See below\n","* Where does the sum() come from?\n","    * Chain rule! Remember how we were summing over each i in the numeric walkthrough.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# So, how are these grad formulas derived?\n","\n","TL;DR: Each backward formula captures one of the multiplications in the chain rule.\n","\n","Let’s say we were doing `out = torch.pow(in, p)`, somewhere in our model and we output a scalar loss. Then:\n","\n","$$\\frac{\\partial loss}{\\partial in_j} = \\sum_i \\frac{\\partial loss}{\\partial out_i} * \\frac{\\partial out_i}{\\partial in_j} $$\n","\n","But wait! pow is a pointwise operation, so `out[i]` does not depend on `in[j]` unless `i == j`.\n","\n","$$\\frac{\\partial loss}{\\partial in_j} = \\frac{\\partial loss}{\\partial out_j} * \\frac{\\partial out_j}{\\partial in_j} $$\n","\n","$$\\frac{\\partial loss}{\\partial in_j} = \\frac{\\partial loss}{\\partial out_j} * p * in_j^{p-1} $$\n","\n","Writing this in a vectorized form we get `grad_input = grad_output * p * in ** (p-1)`.\n","\n","You will see detailed examples on how to derive these formulas in the next section."]},{"cell_type":"markdown","metadata":{},"source":["# What about these saved Tensors that might be needed for backward?\n","\n","Autograd will automatically save all the required data to be able to compute the backward pass.\n","\n","You can actually see these saved properties here:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n"," -->\n","<!-- Title: %3 Pages: 1 -->\n","<svg width=\"279pt\" height=\"577pt\"\n"," viewBox=\"0.00 0.00 278.50 577.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 573)\">\n","<title>%3</title>\n","<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-573 274.5,-573 274.5,4 -4,4\"/>\n","<!-- 140602457417904 -->\n","<g id=\"node1\" class=\"node\">\n","<title>140602457417904</title>\n","<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"156.5,-30 102.5,-30 102.5,0 156.5,0 156.5,-30\"/>\n","<text text-anchor=\"middle\" x=\"129.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">loss</text>\n","<text text-anchor=\"middle\" x=\"129.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> ()</text>\n","</g>\n","<!-- 140602445873312 -->\n","<g id=\"node2\" class=\"node\">\n","<title>140602445873312</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"198,-107 61,-107 61,-66 198,-66 198,-107\"/>\n","<text text-anchor=\"middle\" x=\"129.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SumBackward0</text>\n","<text text-anchor=\"middle\" x=\"129.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n","<text text-anchor=\"middle\" x=\"129.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self_sym_sizes: (2,)</text>\n","</g>\n","<!-- 140602445873312&#45;&gt;140602457417904 -->\n","<g id=\"edge11\" class=\"edge\">\n","<title>140602445873312&#45;&gt;140602457417904</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M129.5,-65.8192C129.5,-57.8154 129.5,-48.5781 129.5,-40.1923\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"133.0001,-40.1824 129.5,-30.1824 126.0001,-40.1825 133.0001,-40.1824\"/>\n","</g>\n","<!-- 140602445876672 -->\n","<g id=\"node3\" class=\"node\">\n","<title>140602445876672</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"267,-195 106,-195 106,-143 267,-143 267,-195\"/>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-183\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">exponent: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2</text>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-150\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self &#160;&#160;&#160;: [saved tensor]</text>\n","</g>\n","<!-- 140602445876672&#45;&gt;140602445873312 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>140602445876672&#45;&gt;140602445873312</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M168.4648,-142.8965C162.434,-134.1676 155.6772,-124.388 149.5053,-115.455\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.3739,-113.4495 143.8099,-107.2117 146.6147,-117.4286 152.3739,-113.4495\"/>\n","</g>\n","<!-- 140602457417744 -->\n","<g id=\"node4\" class=\"node\">\n","<title>140602457417744</title>\n","<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"270.5,-101.5 216.5,-101.5 216.5,-71.5 270.5,-71.5 270.5,-101.5\"/>\n","<text text-anchor=\"middle\" x=\"243.5\" y=\"-89.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self</text>\n","<text text-anchor=\"middle\" x=\"243.5\" y=\"-78.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (2)</text>\n","</g>\n","<!-- 140602445876672&#45;&gt;140602457417744 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>140602445876672&#45;&gt;140602457417744</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M204.5352,-142.8965C213.9285,-129.3009 225.083,-113.1562 233.0453,-101.6318\"/>\n","</g>\n","<!-- 140602445875040 -->\n","<g id=\"node5\" class=\"node\">\n","<title>140602445875040</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"231,-272 142,-272 142,-231 231,-231 231,-272\"/>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-260\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n","</g>\n","<!-- 140602445875040&#45;&gt;140602445876672 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>140602445875040&#45;&gt;140602445876672</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M186.5,-230.6818C186.5,-222.9279 186.5,-213.8855 186.5,-205.1526\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.0001,-205.1389 186.5,-195.1389 183.0001,-205.139 190.0001,-205.1389\"/>\n","</g>\n","<!-- 140602445875472 -->\n","<g id=\"node6\" class=\"node\">\n","<title>140602445875472</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"231,-349 142,-349 142,-308 231,-308 231,-349\"/>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-337\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-326\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n","<text text-anchor=\"middle\" x=\"186.5\" y=\"-315\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n","</g>\n","<!-- 140602445875472&#45;&gt;140602445875040 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>140602445875472&#45;&gt;140602445875040</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M186.5,-307.8654C186.5,-300.0111 186.5,-290.8822 186.5,-282.2879\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.0001,-282.1915 186.5,-272.1915 183.0001,-282.1916 190.0001,-282.1915\"/>\n","</g>\n","<!-- 140602445876336 -->\n","<g id=\"node7\" class=\"node\">\n","<title>140602445876336</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"143,-437 0,-437 0,-385 143,-385 143,-437\"/>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-425\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-414\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-403\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-392\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n","</g>\n","<!-- 140602445876336&#45;&gt;140602445875472 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>140602445876336&#45;&gt;140602445875472</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M107.8867,-384.8965C121.0577,-375.4477 135.945,-364.7677 149.1938,-355.2631\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"151.5439,-357.8848 157.6291,-349.2117 147.4635,-352.197 151.5439,-357.8848\"/>\n","</g>\n","<!-- 140602457417264 -->\n","<g id=\"node8\" class=\"node\">\n","<title>140602457417264</title>\n","<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"98.5,-343.5 44.5,-343.5 44.5,-313.5 98.5,-313.5 98.5,-343.5\"/>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-331.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-320.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (2)</text>\n","</g>\n","<!-- 140602445876336&#45;&gt;140602457417264 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>140602445876336&#45;&gt;140602457417264</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M71.5,-384.8965C71.5,-371.3009 71.5,-355.1562 71.5,-343.6318\"/>\n","</g>\n","<!-- 140602445876192 -->\n","<g id=\"node9\" class=\"node\">\n","<title>140602445876192</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"122,-497.5 21,-497.5 21,-478.5 122,-478.5 122,-497.5\"/>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-485.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 140602445876192&#45;&gt;140602445876336 -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>140602445876192&#45;&gt;140602445876336</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M71.5,-478.2479C71.5,-470.3781 71.5,-458.7851 71.5,-447.4325\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.0001,-447.1879 71.5,-437.1879 68.0001,-447.1879 75.0001,-447.1879\"/>\n","</g>\n","<!-- 140602457417344 -->\n","<g id=\"node10\" class=\"node\">\n","<title>140602457417344</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"98.5,-569 44.5,-569 44.5,-539 98.5,-539 98.5,-569\"/>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-557\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">A</text>\n","<text text-anchor=\"middle\" x=\"71.5\" y=\"-546\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 140602457417344&#45;&gt;140602445876192 -->\n","<g id=\"edge8\" class=\"edge\">\n","<title>140602457417344&#45;&gt;140602445876192</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M71.5,-538.6924C71.5,-529.5067 71.5,-517.7245 71.5,-507.8312\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.0001,-507.703 71.5,-497.7031 68.0001,-507.7031 75.0001,-507.703\"/>\n","</g>\n","<!-- 140602445873408 -->\n","<g id=\"node11\" class=\"node\">\n","<title>140602445873408</title>\n","<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"262,-420.5 161,-420.5 161,-401.5 262,-401.5 262,-420.5\"/>\n","<text text-anchor=\"middle\" x=\"211.5\" y=\"-408.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n","</g>\n","<!-- 140602445873408&#45;&gt;140602445875472 -->\n","<g id=\"edge9\" class=\"edge\">\n","<title>140602445873408&#45;&gt;140602445875472</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M208.534,-401.2122C205.4023,-390.8777 200.305,-374.0566 195.8015,-359.1951\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.0598,-357.8784 192.8101,-349.3232 192.3606,-359.9085 199.0598,-357.8784\"/>\n","</g>\n","<!-- 140602457417424 -->\n","<g id=\"node12\" class=\"node\">\n","<title>140602457417424</title>\n","<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"238.5,-503 184.5,-503 184.5,-473 238.5,-473 238.5,-503\"/>\n","<text text-anchor=\"middle\" x=\"211.5\" y=\"-491\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">B</text>\n","<text text-anchor=\"middle\" x=\"211.5\" y=\"-480\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n","</g>\n","<!-- 140602457417424&#45;&gt;140602445873408 -->\n","<g id=\"edge10\" class=\"edge\">\n","<title>140602457417424&#45;&gt;140602445873408</title>\n","<path fill=\"none\" stroke=\"#000000\" d=\"M211.5,-472.7873C211.5,-460.855 211.5,-444.1423 211.5,-431.1069\"/>\n","<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.0001,-430.8107 211.5,-420.8107 208.0001,-430.8108 215.0001,-430.8107\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.dot.Digraph at 0x7fe08ed74a30>"]},"metadata":{},"output_type":"display_data"}],"source":["torchviz.make_dot(loss, params={'A': A, 'B': B, 'x': x, 'diff': diff,'loss':loss}, show_attrs=True, show_saved=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"zI_CAVQtVHfy"},"source":["<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
